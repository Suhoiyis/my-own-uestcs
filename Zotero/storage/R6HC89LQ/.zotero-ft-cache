学号: 222060132 学校代码: 10336
硕士学位论文
(专业学位)
论文题目: 基于时空分析和对比学习的
运动想象脑电信号解码研究
作 者 姓 名 : 宋飞宇
指 导 教 师 : 孙曜 高级实验师
专业学位类别: 控制工程
专 业 领 域 : 脑机接口
所 在 学 院 : 自动化学院
完 成 时 间 : 2025 年 4 月


杭州电子科技大学硕士学位论文
基于时空分析和对比学习的
运动想象脑电信号解码研究
研 究 生:宋飞宇
指导教师:孙曜 高级实验师
2025 年 4 月


Dissertation Submitted to Hangzhou Dianzi University
for the Degree of Master
Research on Decoding of Motor
Imagery EEG Signals Based on
Spatio-Temporal Analysis and
Contrastive Learning
Candidate: Song Feiyu
Supervisor: S.E. Sun Yao
April, 2025


杭州电子科技大学硕士学位论文
I
摘要
运动想象(Motor imagery,MI)脑机接口(Brain-Computer Interface,BCI)
系统通过解析用户在想象运动时产生的脑电信号(Electroencephalography,EEG),
将用户意图转化为设备控制命令,为运动功能障碍患者提供了一种非侵入式康复
交互解决方案。有效解码脑电信号对于 MI-BCI 系统在实际应用中具有重要意义。
但是,脑电信号由于其固有的非平稳特性,在不同域中呈现出独特的特征表达,
现有特征提取方法在处理时空域信息时未能充分学习到有效特征,分类精度仍有
待提高。此外,固定的 MI 实验范式在获取高质量标注数据上存在难题,这限制
了监督学习方法在实际应用中的分类精度与泛化性能。本文对运动想象脑电信号
的时空特征学习问题和标注数据稀缺问题展开研究,具体工作如下:
(1)针对运动想象脑电信号的时空特征学习问题,本文构建了一种多尺度
时空动态注意力网络(Multi-Scale Spatio-Temporal Dynamic Attention Network,
MSTDAN)。首先,该网络结合并行多尺度卷积和全局注意力机制,提取不同时
间尺度下的浅层时域特征并进行动态自适应融合,有效捕获了特征间的非线性关
联;其次,在空间特征提取上,设计基于方差的统计注意力机制,充分利用脑电
信号的统计特性进行通道权重自适应调整,增强对关键空间特征的感知能力;最
后,使用并行多尺度卷积提取深层时域特征,设计特征重组机制建立不同时间尺
度特征间的动态关联,以此增强深层时域特征的捕获能力。实验结果表明,
MSTDAN 模型在 BCIC-IV-2a、HGD 数据集上的四分类任务平均分类准确率分别
达到 82.06%和 95.44%,在 BCIC-IV-2b 数据集上的二分类任务,模型平均分类准
确率达到 88.06%。
(2)针对标注数据稀缺问题,本文基于对比学习构建了一种无负样本的运
动想象脑电信号解码框架。预训练阶段的设计包括数据增强、编码器网络、投影
网络和损失函数四部分。基于运动想象脑电信号特性设计数据增强方法,使用线
性探测策略评估不同数据增强组合对特征学习的影响,实验结果表明,随机裁剪
与随机带通滤波的组合策略在所有数据集上均表现最佳,为对比学习在 MI-BCI
中的应用提供了有效的数据增强方案。将 MSTDAN 网络作为编码器,从无标签
MI-EEG 数据中提取时空特征。使用具有单个隐藏层的多层感知器构建投影网络。
使用 Barlow Twins 损失函数进行对比损失计算,优化表示向量的互相关矩阵实
现对比学习,减少嵌入向量间冗余信息,消除传统对比学习对大量负样本的依赖,
显著降低了计算复杂度和对批量大小的敏感性。下游任务中,使用“预训练-微


杭州电子科技大学硕士学位论文
II
调”的方法进行模型训练,实验结果表明,该模型在 BCIC-IV-2a、2b、HGD 三
个数据集上分别达到 79.85%(跨会话四分类)、86.27%(跨会话二分类)和 76.54%
(跨被试四分类)的准确率。标注数据比例影响分析表明,仅需 50%标注数据即
可达到全量数据 94%以上的性能,且在跨被试任务中表现尤为突出。
关键词:脑机接口,运动想象,时空特征,对比学习,无负样本


杭州电子科技大学硕士学位论文
III
Abstract
Motor imagery-based brain-computer interface (MI-BCI) systems enable the
conversion of user intentions into device control commands through the analysis of
electroencephalography (EEG) signals generated during motor imagery, providing a
non-invasive rehabilitation solution for patients with motor disabilities. Effective
decoding of EEG signals is of significant importance for practical applications of MI
BCI systems. However, due to the inherent non-stationary characteristics of EEG
signals, which exhibit unique feature expressions across different domains, existing
feature extraction methods fail to adequately learn effective features when processing
spatio-temporal information, leaving room for improvement in classification accuracy.
Additionally, the fixed MI experimental paradigm presents challenges in acquiring
high-quality labeled data, limiting the classification accuracy and generalization
performance of supervised learning methods in practical applications. This thesis
investigates solutions for spatio-temporal feature learning and labeled data scarcity in
motor imagery EEG signals, with specific work as follows:
(1) Aiming at the spatio-temporal feature learning problem of motor imagery EEG
signals, this thesis constructs a Multi-Scale Spatio-Temporal Dynamic Attention
Network (MSTDAN). First, the network combines parallel multi-scale convolutions
with global attention mechanisms to extract shallow temporal features at different time
scales and perform dynamic adaptive fusion, effectively capturing non-linear
correlations between features. Second, for spatial feature extraction, a variance-based
statistical attention mechanism is designed to fully utilize the statistical properties of
EEG signals for adaptive adjustment of channel weights, enhancing the perception
capability for key spatial features. Finally, parallel multi-scale convolutions are
employed for deep temporal feature extraction, with a feature reorganization
mechanism designed to establish dynamic correlations between features at different
time scales, thereby enhancing the capability for capturing deep temporal features.
Experimental results demonstrate that the MSTDAN model achieves average
classification accuracies of 82.06% and 95.44% for four-class tasks on the BCIC-IV-2a
and HGD datasets, respectively, and an average classification accuracy of 88.06% for
binary classification tasks on the BCIC-IV-2b dataset.


杭州电子科技大学硕士学位论文
IV
(2) Aiming at the labeled data scarcity problem, this thesis develops a negative
sample-free contrastive learning framework for motor imagery EEG signal decoding.
The pre-training phase design comprises four components: data augmentation, encoder
network, projection network, and loss function. Data augmentation methods are
designed based on the characteristics of motor imagery EEG signals, with a linear
probing strategy employed to evaluate the impact of different data augmentation
combinations on feature learning. Experimental results indicate that the combination
strategy of random cropping and random bandpass filtering performs optimally across
all datasets, providing an effective data augmentation solution for applications of
contrastive learning in MI-BCI. The MSTDAN network serves as the encoder for
extraction of spatio-temporal features from unlabeled MI-EEG data. A multi-layer
perceptron with a single hidden layer is used to construct the projection network. The
Barlow Twins loss function is utilized for contrastive loss calculation, optimizing the
cross-correlation matrix of representation vectors to implement contrastive learning,
reducing redundant information between embedding vectors, and eliminating the
dependence on large numbers of negative samples in traditional contrastive learning,
significantly reducing computational complexity and sensitivity to batch size. In
downstream tasks, a "pre-training-fine-tuning" approach is employed for model
training. Experimental results indicate that the model achieves accuracies of 79.85%
(cross-session four-class), 86.27% (cross-session binary), and 76.54% (cross-subject
four-class) across the BCIC-IV-2a, 2b, and HGD datasets. Analysis of labeled data
proportions demonstrates that only 50% labeled data is needed to achieve over 94% of
the performance obtained with full data, with particularly outstanding performance in
cross-subject tasks.
Keywords: Brain-Computer Interface, Motor Imagery, Spatio-Temporal Features,
Contrastive Learning, Negative-Sample-Free


目录
第 1 章 绪论...............................................................................................1
1.1 研究背景与意义...............................................................................1
1.2 国内外研究现状...............................................................................2
1.2.1 基于机器学习的 MI-EEG 解码研究 ........................................2
1.2.2 基于深度学习的 MI-EEG 解码研究 ........................................3
1.3 研究内容与章节安排.......................................................................4
1.3.1 研究内容.....................................................................................4
1.3.2 章节安排.....................................................................................5
第 2 章 相关基础理论 ..............................................................................7
2.1 运动想象脑电信号的产生机制与特性 ..........................................7
2.2 事件相关去同步/同步现象 .............................................................7
2.3 卷积神经网络相关理论基础 ..........................................................8
2.4 对比学习相关理论基础.................................................................10
2.5 本章小结.........................................................................................12
第 3 章 基于多尺度卷积与注意力机制的 MI-EEG 分类 ....................13
3.1 引言.................................................................................................13
3.2 多尺度时空动态注意力网络(MSTDAN).....................................14
3.2.1 MDFS 模块................................................................................15
3.2.2 SVA 模块 ...................................................................................17
3.2.3 MTFM 模块 ...............................................................................19
3.3 实验设置及结果分析.....................................................................21
3.3.1 数据集介绍...............................................................................21
3.3.2 评价指标...................................................................................25
3.3.3 实验设置...................................................................................25
3.3.4 对比实验...................................................................................26
3.3.5 消融实验...................................................................................33
3.3.6 超参数敏感度分析...................................................................36
3.4 本章小结.........................................................................................39
第 4 章 基于无负样本对比自监督学习的 MI-EEG 分类 ....................40
4.1 引言.................................................................................................40
4.2 数据增强.........................................................................................41
4.3 MSTDAN 编码网络.......................................................................43
4.4 投影网络.........................................................................................43
4.5 Barlow Twins 损失函数 .................................................................44


4.6 下游任务.........................................................................................45
4.7 实验设置及结果分析.....................................................................45
4.7.1 实验设置...................................................................................45
4.7.2 数据增强影响分析...................................................................46
4.7.3 对比实验...................................................................................48
4.7.4 投影网络参数影响分析...........................................................52
4.7.5 标注数据比例影响分析...........................................................55
4.7.6 编码网络输出特征可视化.......................................................57
4.7.7 超参数敏感度分析...................................................................58
4.8 本章小结.........................................................................................59
第 5 章 总结与展望 ................................................................................61
5.1 总结.................................................................................................61
5.2 展望.................................................................................................62
参考文献...................................................................................................63


杭州电子科技大学硕士学位论文
1
第 1 章 绪论
1.1 研究背景与意义
脑机接口(Brain-Computer Interface,BCI)系统通过解释用户的神经活动模
式,实现了用户与机器之间的非肌肉交流[1]。在脑机接口应用中,脑电信号
(Electroencephalogram,EEG)因其非侵入性和成本效益高的特点而广泛应用于
研究中。运动想象(Motor Imagery,MI)[2]是指在没有任何实际身体运动的情况
下,在大脑中模拟动作执行过程的认知活动。当参与者想象移动其身体部位时,
大脑特定区域会产生能量变化,这些变化可以通过脑电信号记录下来,并用于识
别运动意图[3]。基于运动想象的脑机接口(MI-BCI)因其能够从脑电信号中解码
用户运动意图的能力而受到广泛关注,已成功应用于中风康复[4]、轮椅控制[5]和
外骨骼机器人手臂控制[6]等各个领域,MI-BCI 系统结构如图 1.1 所示。
图 1.1 MI-BCI 系统
当患者想象执行特定动作时,系统通过识别相应的脑电模式,将其转化为外
部设备的控制信号或视觉反馈,形成闭环神经反馈系统[7]。这种机制能够有效促
进大脑皮层的可塑性重组[8]。临床研究数据显示,相比传统康复方法,结合 MI
BCI 的康复训练可使患者运动功能恢复率提高约 20-30%[9],并能有效缩短康复
周期。MI-BCI 在改善完全瘫痪患者的生活质量中具有不可替代的价值[10],患者
能够通过"思考"直接控制外部辅助设备,实现一定程度的行为自主性[11]。
运动想象脑电信号分类是 MI-BCI 的核心组成部分,其准确性直接决定了系
统的实用性。准确解码用户的运动想象意图对于辅助设备控制、神经康复和通信


杭州电子科技大学硕士学位论文
2
辅助系统等应用具有重要价值[12]。运动想象脑电信号因其固有特性在分类上面
临诸多挑战。脑电信号属于微弱生物电信号,其幅值通常仅为几微伏至数十微伏,
信噪比低,易受各种内外部因素干扰[13];脑电信号具有显著的非平稳性和个体差
异性,不同受试者甚至同一受试者在不同时间的脑电模式都可能存在较大差异
[14];运动想象与实际运动相比,相关脑区的激活程度较弱,信号特征不够明显[15]。
运 动 想 象 脑 电 信 号 在 时 间 维 度 上 会 产 生 事 件 相 关 同 步 ( Event-Related
Synchronization,ERS)和事件相关去同步(Event-Related Desynchronization,ERD)
现象,该现象表现为:在运动想象过程中特定频段的脑电节律功率相对于基线状
态的增加或减少[16]。在空间维度上,这些神经活动主要集中于大脑感觉运动皮层
区域,不同身体部位的运动想象会激活对应的皮层区域,形成特定的空间分布模
式[17]。这些时空特征包含了丰富的运动想象意图信息,对准确分类至关重要。
在实际应用中,高质量标注数据的获取也是一个亟待解决的问题。受试者需
要进行大量重复的运动想象任务,长时间的信号采集容易让其产生疲劳,影响信
号质量[18];运动想象是一个主观过程,无法直接观察,难以确保每次想象任务的
一致性和有效性[19],进一步增加了高质量标注数据的获取难度。
因此,研究开发能够准确提取运动想象脑电信号时空特征、减少对标注数据
依赖的分类方法,对推进脑机接口技术的实际应用具有重要意义。本文研究旨在
通过创新的特征提取网络和对比学习策略,提高运动想象脑电信号分类的准确性
和泛化能力,为脑机接口技术的发展和应用提供新的解决方案。
1.2 国内外研究现状
1.2.1 基于机器学习的 MI-EEG 解码研究
在之前关于 MI-BCI 的研究中,小波去噪被广泛用于去除噪声[20]。最近,结
合主成分分析和小波去噪的 MSPCA 方法已被应用于去噪[21]。与运动想象相关的
特征基于去噪后的 EEG 信号,从三个主要领域(空间、时间和频谱)或组合领
域中提取。各种算法,如共空间模式(Common Spatial Pattern,CSP)、时域参数
和功率谱密度[22-24]已被用于 MI 特征提取。其中,CSP 利用空间滤波器识别 EEG
信号中的不同模式,被广泛用于 MI 特征提取[25-27]。研究者开发了一种滤波器组
CSP(Filter Bank Common Spatial Pattern,FBCSP),以克服 CSP 的频带依赖性
[28]。该方法识别每个频带上的 CSP,比较频带之间 CSP 特征的互信息,以选择
唯一的频带[26, 28, 29]。
在分类方法方面,主要采用线性判别分析[25, 27, 30-32](Linear Discriminant
Analysis,LDA)和支持向量机[26, 28, 29, 33, 34](Support Vector Machines,SVM)。
然而,由于受试者间和受试者内的差异性,这些方法往往面临泛化性能较低的问


杭州电子科技大学硕士学位论文
3
题[35]。为解决这一问题,研究者从两种方向出发:一是通过使用各种公共数据集
增加受试者数量[36, 37];二是开发能分析和分类脑电数据且具备良好泛化性的深
度学习模型[38, 39]。
1.2.2 基于深度学习的 MI-EEG 解码研究
近年来,研究者们已经提出了各种基于深度学习的 MI-EEG 解码方法来实现
优异的分类性能。深度学习方法通过从 MI-EEG 中自动提取复杂特征,为 MI-BCI
系统提供了一种端到端解决方案[40-43]。DeepConvNet[44, 45]采用多个卷积核的卷积
层提取时间和空间特征。Sakhavi 等人[46]利用 FBCSP 进行特征提取,将提取到的
特征输入卷积神经网络(Convolutional Neural Network,CNN)进行分类。Lawhern
等人[47, 48]引入了一种紧凑型网络 EEGNet,采用深度可分离卷积进行时空特征提
取。ShallowConvNet[45, 49]模型利用卷积层对脑电信号进行频率和空间滤波。这些
基于 CNN 的模型在性能上优于传统的运动想象分类方法。然而,由于缺乏提取
高度判别性特征的有效机制,在性能提升上存在局限性。
注 意 力 机 制 的 引 入 为 运 动 想 象 脑 电 信 号 解 码 提 供 了 新 的 解 决 方 法 。 TS
SEFFNet[50]将基于小波包子带能量比的通道注意力模块与时间注意力机制相结
合,实现了对关键时间段和通道的自适应筛选。LMDANet[51]创新性地将自定义
通道重校准模块与来自 ECA-Net[52]的特征通道注意力模块相结合,有效增强了
对关键通道信息的提取能力。Wimpff 等人[53]系统地将不同类型的注意力机制应
用于提出的 BaseNet 架构,通过大量对比实验得出:空间-通道混合注意力策略
在不增加显著计算成本的情况下能将模型性能提升约 7%。M-FANet[54]采用小卷
积核尺寸提取局部空间信息,并巧妙运用 SE 模块[55]从多个角度提取信息,在跨
受试者分类任务中表现出优异的泛化能力。这些方法通过将注意力机制应用于神
经网络提取的深层特征,显著提高了运动想象解码的精度和鲁棒性。
图卷积网络(Graph Convolutional Network,GCN)被认为有望用于模拟 EEG
电极之间的关系。虽然 GCN 已被广泛应用于基于 EEG 的情感识别脑机接口,但
在 MI-EEG 信号识别方面尝试较少。Hou 等人[56]和 Wang 等人[57]分别使用先验知
识和可学习网络参数构建图网络。这些 GCN 方法将每个脑电极视为节点,边代
表电极之间的连接。尽管这种方法在一定程度上捕获了电极之间的空间关系,但
它忽略了每个电极内的频谱特征,而这些特征对有效识别 MI-EEG 至关重要。
广泛的研究工作集中在从高时间分辨率的 EEG 信号中提取更有效的时间特
征上。Transformer 模型因其能够感知全局依赖关系在自然语言处理和计算机视
觉 领 域 取 得 了 巨 大 成 功 [58] , 也 逐 渐 应 用 于 运 动 想 象 解 码 。 Conformer[59] 堆 叠
Transformer 块,通过 CNN 提取局部时间特征,再从中提取长期依赖特征。
ATCNet[60]将 Transformer 与时间卷积网络(Temporal Convolutional Network,TCN)


杭州电子科技大学硕士学位论文
4
集成,提取长程时间特征,获得良好的分类性能。MSVTNet[61]使用 CNN 提取多
尺度局部特征,再使用 Transformer 捕获全局特征。然而,Transformer 模型对大
型训练数据集的需求与 MI-EEG 任务中可用的有限数据之间存在固有冲突,同时
Transformer 模型参数量大、计算成本高,使其难以用于实时 MI 解码。
监督学习方法在 MI-EEG 解码中取得了显著进展,但这些方法仍主要依赖于
大量标注数据进行监督训练,而高质量标注数据的获取在 MI-BCI 系统中面临诸
多挑战。为了解决标注数据匮乏的问题,研究者们开始探索将自监督学习(Self
supervised Learning, SSL)应用于 MI-EEG 解码。
自监督学习是一种从无标注数据中获取有用表示的方法[62, 63],包括借口任
务[64]、对比学习[65]和掩码预测任务[66]等多种方法。SSL 主要应用于计算机视觉,
其在信号处理中的应用仍处于早期阶段[67, 68]。与监督学习不同,SSL 方法可以在
没有标注数据的情况下实现有效的表示学习。SSL 利用数据中的固有结构和信息,
以解决标签不一致性以及受试者间和受试者内的差异性问题。这使该技术特别适
用于标记困难且成本高昂的 EEG 信号,从而增强泛化能力[69, 70]。SSL 已经有效
地用于基于 EEG 信号的分类任务,包括睡眠阶段分类、情绪识别和 MI 分类[67,
69-73]。
SSL 在 MI-BCI 领域的应用研究相对较少,集中在借口任务[74-76]和对比学习
[62, 77]。在利用借口任务的研究中,引入了预训练模型的方法,要么随机重排 EEG
信号的部分,要么根据过去信号预测未来信号[74, 75]。尽管这些方法可以从未标注
数据中学习固有特征,但它们在设计上存在复杂性,在泛化方面也存在局限性[75,
78, 79]。应用对比学习的研究通过使用 SimCLR 框架提高了跨会话 MI 分类的特征
学习鲁棒性和泛化能力[62, 65, 77]。然而,SimCLR 依赖于负样本策略,在实际应用
中,负样本的选择与生成存在主观性偏差且计算成本较高[69, 80-82]。
1.3 研究内容与章节安排
1.3.1 研究内容
当前运动想象脑电信号解码研究中,在特征提取与分类上取得了显著进展,
但仍存在以下局限性:
(1)在 MI 时空特征提取方面,多尺度时间特征在进行交互融合时采用简
单拼接,忽略特征间的非线性关联;在空间特征提取上,现有的大部分工作仅采
用核大小为(通道数,1)的卷积整合多个电极通道上的信息,不足以提取有效
的空间特征;深层时域特征提取往往采用串行提取结构导致长程依赖信息丢失。
(2)针对 MI 分类,当前研究大多使用监督学习且模型进行分类时依赖标
注数据。标签不正确或数据不足,均可导致性能下降和过拟合,这限制了模型的


杭州电子科技大学硕士学位论文
5
实用性和可靠性。自监督学习被证明可以解决这类问题,但目前在 MI-BCI 领域
的应用研究相对较少,在数据增强策略设计、对比学习效率等方面存在局限性。
其中常用的对比学习方法,需要大量负样本对,计算效率低且训练不稳定,限制
了其在实际 BCI 系统中的应用。
针对上述局限性,本文主要从时空特征提取和对比学习上进行研究,主要成
果如下:
(1)构建了一种多尺度时空动态注意力网络(Multi-Scale Spatio-Temporal
Dynamic Attention Network,MSTDAN)。首先,该网络结合并行多尺度卷积和全
局注意力机制,提取不同时间尺度下的浅层时域特征并进行动态自适应融合,有
效捕获了特征间的非线性关联;其次,在空间特征提取上,设计了基于方差的统
计注意力机制,充分利用脑电信号的统计特性进行通道权重自适应调整,增强对
关键空间特征的感知能力;最后,使用并行多尺度卷积提取深层时域特征,设计
了特征重组机制来建立不同时间尺度特征间的动态关联,以此增强深层时域特征
的捕获能力。
(2)构建了基于 Barlow Twins 的无负样本运动想象脑电信号解码框架。在
预训练策略上,系统性设计了五种针对 MI-EEG 特性的数据增强方法,通过线性
探测实验确定了随机裁剪与随机带通滤波的最优组合;采用 MSTDAN 作为特征
编码器,配合单隐藏层投影网络构建特征映射机制;引入 Barlow Twins 损失函
数,通过互相关矩阵优化实现无负样本对比学习。在下游适配上,建立了"预训
练-微调"的两阶段训练范式,实现预训练知识向具体分类任务的有效迁移。
1.3.2 章节安排
本文共分为 5 个章节,整体结构如图 1.2 所示,各章节内容简介如下:
第 1 章:绪论。阐述研究背景与意义,总结国内外研究现状,分析目前在特
征提取与分类中存在的局限性,介绍本文的主要研究内容和章节安排。
第 2 章:相关基础理论及数据集介绍。介绍运动想象脑电信号的产生机制与
特性,描述事件相关去同步/同步现象,详细介绍卷积神经网络和对比学习的相
关理论,为后续章节提供基础理论支撑。
第 3 章:基于多尺度卷积与注意力机制的 MI-EEG 分类。针对现有方法在时
空特征提取方面的局限性,提出一种多尺度时空动态注意力网络(MSTDAN)。
详细介绍模型的整体设计和各功能模块的具体实现。通过对比实验、消融实验和
超参数敏感度分析,系统评估模型在 MI-EEG 特征提取上的性能和有效性。
第 4 章:基于无负样本对比自监督学习的 MI-EEG 分类。针对标注数据稀缺
的问题,基于对比学习构建了一种无负样本的 MI-EEG 解码框架。详细介绍预训
练阶段中的数据增强、编码器网络、投影网络和损失函数四部分。下游任务中,


杭州电子科技大学硕士学位论文
6
使用线性探测评估不同数据增强策略对特征提取的影响,使用“预训练-微调”的
训练方法,通过跨会话和跨被试实验,全面评估模型性能。系统分析标注数据比
例、投影网络参数及超参数对模型性能影响。
第 5 章:总结与展望。总结本文的主要研究成果,客观分析当前工作的局限,
指出未来可能的研究方向。
图 1.2 论文整体结构图
第1章 绪论
MI-EEG研究背景及意义、国内外研究现状、研究内容、章节安排
第2章 相关基础理论及数据集介绍
MI-EEG产生机制与特性、卷积神经网络与 对比学习基础理论、数据集与评价指标
局限一: 时空特征提取 不充分
局限二: 标注数据稀缺
第3章 基于多尺度卷积和注意 力机制的MI-EEG分类
多尺度动态特征选择(MDFS) 基于方差统计的注意力(SVA) 多尺度时间特征混合(MTFM) 跨会话实验结果分析
第4章 基于无负样本对比自监 督学习的MI-EEG分类
无负样本对比自监督学习框架构建: 预训练(数据增强、编码网络、投影 网络、损失函数) 下游任务(线性探测、微调) 跨会话、跨被试实验结果分析
第5章 总结与展望
研究成果总结、未来研究方向


杭州电子科技大学硕士学位论文
7
第 2 章 相关基础理论
2.1 运动想象脑电信号的产生机制与特性
运动想象是指在不进行实际肢体运动的情况下,由被试在大脑中模拟动作执
行过程的认知活动[2]。MI-EEG 主要源于大脑皮层锥体细胞的同步活动变化[83],
Hamedi 等人[84]证实,这些变化可通过容积传导传播至头皮,形成可被 EEG 电极
记录的电位变化。Pfurtscheller 和 Neuper 等人[85]的研究证实,运动想象与实际运
动执行激活了相似的皮层区域,但激活程度较弱。运动想象激活了包括初级运动
皮层、前运动皮层、辅助运动区以及顶叶区域在内的负责神经网络[86]。Kasess 等
人[87]发现,运动想象过程中辅助运动区对初级运动皮层存在抑制性调控,解释了
运动想象与实际运动为何激活程度存在差异。
MI-EEG 为典型的生物电信号,具有多种特性:
(1)信噪比低:Minguillon 等人[88]指出,MI-EEG 振幅通常仅为几微伏至数
十微伏,远低于肌电和眼电等生理伪迹,容易被背景噪声和各种伪迹掩盖。
(2)非线性和非平稳性:MI-EEG 是典型的非线性和非平稳信号,其统计特
性随时间变化[12]。这种非平稳性源于注意力波动、疲劳效应以及大脑状态的自发
变化等多种因素[89],导致特征分布随时间漂移。
(3)节律性:在运动想象任务中,产生的脑电信号可根据节律分为多个频
带,每个频带与不同的大脑功能状态相关联,具体的特性如表 2-1 所示。
表 2-1 MI-EEG 频带划分及特性
脑电节律 频率范围(Hz) 特性
δ 波 0.5-4 主要出现在深度睡眠状态
θ 波 4-8 与记忆处理、情感处理和注意力相关
α 波 8-13 通常在清醒、放松状态下出现,特别是闭眼时在枕区明显
β 波 13-30 与清醒、专注状态相关,常见于额叶和中央区域
γ 波 >30 与高级认知过程、信息整合和感知绑定相关
(4)个体差异显著:Blankertz 等人[90]研究表明,不同受试者的运动想象脑
电模式存在明显差异,甚至同一受试者在不同时间的记录也有变化。
2.2 事件相关去同步/同步现象
事件相关去同步(Event-Related Desynchronization,ERD)和事件相关同步
(Event-Related Synchronization,ERS)是脑电信号中反映大脑皮层神经网络活
动状态变化的重要神经电生理现象。ERD 表现为特定频段脑电活动功率的降低,
当个体执行实际运动或进行运动想象时,相应的运动皮层区域会被激活,导致该


杭州电子科技大学硕士学位论文
8
区域特定频段,主要是 mu 节律(8-12Hz)和 beta 频段(13-30Hz)的脑电能量
下降。这种能量下降反映了参与运动控制的神经网络从静息状态转变为激活状态
的过程。与之相对应的是 ERS 现象,表现为特定频段脑电活动功率的增加。当
个体停止运动或运动想象,进入静息状态时,先前被激活的运动皮层区域会恢复
至基线状态,甚至出现频带能量暂时高于基线水平的"反弹"效应。
在时间维度上,ERD 通常在运动想象开始后约 0.5-2 秒内出现,并在整个想
象过程中持续存在;而 ERS 则多在运动想象结束后 1-3 秒内达到峰值。运动想
象任务中的 ERD/ERS 现象呈现出明显的空间特异性,与大脑皮层的功能定位紧
密相关。当被试进行左手运动想象时,主要在大脑右侧中央区(C4 电极附近)
可观察到显著的 mu 节律和 beta 频段 ERD 现象;而右手运动想象则主要激活大
脑左侧中央区(C3 电极附近),同样表现为 mu 节律和 beta 频段的 ERD 模式;
双脚运动想象则与前两者不同,主要在大脑中央顶区(Cz 电极附近)引起显著
的 beta 频段 ERD 现象;舌头运动想象则在大脑中央前部区域诱发特定的 ERD
模式。
2.3 卷积神经网络相关理论基础
卷积神经网络(Convolutional Neural Network,CNN)因其层级化特征提取
结构广泛应用于图像处理、语音识别和时序信号分析等领域。CNN 的基本结构
如图 2.1 所示,通常包含多个卷积层和池化层的交替堆叠,后接一个或多个全连
接层,最终连接到输出层。
图 2.1 CNN 基本结构
前向传播和反向传播是 CNN 训练过程中的核心机制。输入数据依次通过各
层处理,最终生成预测输出,期间通过反向传播对网络参数进行不断优化。利用
损失函数计算预测输出与真实标签之间的误差,误差梯度从输出层逐层反向传递
至各个网络层。最后,基于计算得到的梯度信息,使用优化算法更新网络权重参
数。
输入层对数据进行预处理和格式转换的操作,对于 MI-EEG,输入层通常将
其构建为通道×时间的二维矩阵结构。数据在输入网络前往往经过标准化或归一
化处理,有助于加速网络收敛并增强稳定性。
输入层 卷积层 池化层 卷积层 池化层 卷积层 池化层
...
全 连 接 层
输出层
损 失 计 算
前向传播
反向传播


杭州电子科技大学硕士学位论文
9
特征提取部分集中在卷积层,卷积层中设计尺寸固定的卷积核,对输入数据
按照指定步长移动并计算内积,生成特征图。卷积操作具有共享权重和局部感知
的特性,多个卷积核的并行使用使得网络能同时捕获多种特征维度的信息。本文
研究中主要使用一维卷积与二维卷积,其具体操作如图 2.2 所示。卷积核在特征
图上移动时,对应区域内的元素与卷积核权重相乘并求和,形成输出特征图的相
应元素。
池化层主要进行降维和特征增强,分为平均池化和最大池化,如图 2.3 所示。
池化操作使用固定大小的滑动窗口扫描输入特征图,对每个窗口内的特征数据执
行汇总计算,降低特征维度的同时保留关键信息,帮助模型降低计算复杂度,增
强泛化能力。
图 2.2 卷积操作(一维卷积和二维卷积)
1112
1203
0125
0211 112
201
101
8
1*1+1*1+2*1+2*1+0*2 +1*0+1*0+0*1+1*2=8
1112
1203
0125
0211
101 2
1*1+0*1+1*1=2
一维卷积
二维卷积


杭州电子科技大学硕士学位论文
10
图 2.3 池化操作(平均池化和最大池化)
经过多层卷积和池化之后的特征通过全连接层映射到分类空间。与局部连接
的前层不同,全连接层中每个神经元均与上一层所有神经元建立连接,将特征表
示转换为目标输出。因其密集连接特性,全连接层参数量大幅增加,使用 dropout
等正则化技术,避免模型过拟合。
多分类任务中,输出层通常使用 Softmax 激活函数将神经网络的原始输出转
化为概率分布,进行类别预测。与传统线性模型不同,激活函数的使用帮助网络
引入非线性变换,使模型能够学习复杂的非线性决策边界,提高分类性能本文研
究中在模型设计上使用了 sigmoid、tanh、Softmax 和 ELU 函数,在参数影响分
析中引入了 ReLU 和 Leaky ReLU 函数,这些函数的图像如图 2.4 所示。
图 2.4 不同激活函数图像
2.4 对比学习相关理论基础
自监督学习(SSL)利用数据固有结构和信息生成“伪标签”[65],使模型能够
在无需或仅需少量标注数据的情况下构建有效的特征表示。自监督学习通常由预
训练和下游任务两个阶段组成。模型从预训练阶段中学习数据的通用特征表示;
2321
1201
4124
5211
1
32
2
2
54
3
平均池化
最大池化


杭州电子科技大学硕士学位论文
11
在下游任务阶段中,预训练模型通过线性探测(Linear Probing)或微调(Fine
tuning)等方式适配到具体任务中。通过"预训练-微调"策略,模型能够从大量未
标注数据中提取有用特征,使在标注数据有限的情况下仍能保持良好的性能。
根据预训练任务的设计方式,自监督学习方法主要分为以下几类:
(1)生成式方法:通过重建输入数据或其变换版本来学习特征表示,如自
动编码器[91](Autoencoders)和生成对抗网络[92](GANs)等。
(2)预测式方法:通过设计特定的预测任务,使模型学习有效的特征表示。
Gidaris 等[93]提出的旋转预测方法通过预测图像的旋转角度,学习语义相关的视
觉特征。Oord 等[94]设计的对比预测编码(Contrastive Predictive Coding,CPC)
通过预测时间序列的未来表示来捕获数据的时序依赖性。
(3)对比式方法:通过最大化相似样本表示之间的相似性,最小化不同样
本表示之间的相似性的方法来学习判别性特征。Chen 等[65]提出的 SimCLR 通过
数据增强和非线性投影头简化了对比学习框架。He 等[95]开发的 MoCo 引入动量
编码器和队列机制提高训练效率和表示质量。Grill 等[96]首次提出不使用负样本
的 BYOL 框架,实现有效地特征学习。
对比学习(Contrastive Learning)作为自监督学习的一种主要方法,其核心
思想是通过比较样本对之间的相似性与差异性来学习有效的特征表示。该方法基
于一个直观假设:来自同一数据样本的不同增强视图应当在特征空间中彼此接近,
来自不同数据样本的表示应当相距较远[97]。
对比学习框架包括以下组成部分:
(1)数据增强(正负样本对构建):对原始数据应用不同的增强策略,从同
一原始样本生成的不同视图被视为正样本对(Positive Pairs),来自不同原始样本
的视图则构成负样本对(Negative Pairs)。与传统监督学习不同,数据增强不再
单纯用于扩充训练样本,更多的是作为构建预训练任务的核心机制。增强策略的
有效性直接关系到模型的特征学习质量。研究表明,采用互补的增强组合方法通
常比单一增强方法效果更佳。
(2)特征提取:使用编码器从增强后的样本中提取特征表示。编码网络作
为特征提取的核心组件,其模型架构设计直接决定了对比学习的上限。与传统监
督学习不同,对比学习中的编码器需要更强的表示能力,以捕获数据的固有结构
而非仅关注判别性特征。研究表明,对比学习中的编码器通常要求比监督学习更
深的结构,这是因为自监督任务需要更强大的特征提取能力来弥补缺少标签指导
的不足。
(3)特征映射:通过投影网络(Projection Head)将特征映射到新的空间,
使映射后的特征表示充分捕获样本间的语义相似性,优化对比学习的目标函数性


杭州电子科技大学硕士学位论文
12
能。投影网络一般使用多层感知机(Multilayer Perceptron,MLP)结构,由多个
全连接层和非线性激活函数组成。投影网络仅在预训练阶段使用,下游任务使用
编码器输出的特征,防止特征表示过度适应预训练中的判别任务。
(4)对比损失计算:对比损失函数是对比学习的核心,其基本原理为最大
化正样本对之间的相似度,同时最小化不同样本间的相似度。通过构建特征空间,
使同一样本的不同增强视图在此空间中紧密聚集,而不同样本的表示相距较远。
实际操作中,对比损失通常先使用余弦相似度或欧氏距离等方法计算样本表
示之间的相似性,然后通过优化目标函数调整网络参数,使特征表示满足预期的
分布特性。对比损失函数的设计通常需要解决两个关键问题:如何有效区分不同
样本的表示,以及如何防止表示坍塌(即所有样本映射到相同或极为相似的表示)。
2.5 本章小结
本章系统阐述了运动想象脑电信号(MI-EEG)的理论基础。详细介绍了 MI
EEG 的产生机制,其主要源于大脑皮层锥体细胞的同步活动变化,具有低信噪
比、非线性非平稳、明显节律性和显著个体差异等特性。其次,介绍运动想象过
程中存在的事件相关去同步/同步想象。然后,介绍卷积神经网络(CNN)的基本
原理,包括其层级结构、前向与反向传播机制、卷积与池化操作以及激活函数的
作用。最后详细介绍对比学习的理论框架,阐明了数据增强、特征提取、特征映
射和对比损失计算的作用以及原理。本章内容为后续 MI-EEG 特征提取与分类模
型的设计与优化奠定了理论基础。


杭州电子科技大学硕士学位论文
13
第 3 章 基于多尺度卷积与注意力机制的 MI-EEG 分类
3.1 引言
MI-EEG 本质上是大脑神经元群体活动的电生理表现。在 MI 任务中,大脑
皮层感觉运动区域的神经元群体以特定的时间和空间模式激活。因此,MI-EEG
具有明显的时空特征。在时间维度上,MI-EEG 呈现出高度的动态性,短时、中
时和长时程的信号变化均包含丰富的任务相关信息,反映了 MI 过程中的准备、
执行和恢复等不同时间阶段的神经活动变化;从空间维度看,不同类型的 MI 会
激活相应的功能脑区。例如,左手运动想象主要激活右侧运动皮层,右手运动想
象则主要激活左侧运动皮层。更重要的是,MI 任务通常涉及多个脑区的协同激
活,不同脑区产生的信号强度和模式各不相同,脑区间的相互作用形成了复杂的
空间分布模式,构成了区分不同类型 MI 的关键特征。因此,设计能够有效捕获
MI-EEG 时空特征的方法,对于提升 MI 分类模型的性能具有重要意义。
目前,针对 MI-EEG 中的时域特征、空间特征以及深层时域特征的提取方法
已有多种:EEG-TCNet[100]利用扩张卷积逐层扩大感受野以增强对长时程特征的
提取能力,但其串行的特征提取结构使得浅层特征需要经过多层网络传递才能获
取长时程的特征表达,容易造成有效信息的丢失;EEG-Inception[101]通过并行多
尺度时间卷积同时提取不同时间尺度特征,在一定程度上缓解了特征传递损耗的
问题,但其简单的特征拼接方法未能有效整合多尺度时域特征间的相互关系;Liu
等[102]提出的 TCACNet 引入时间与通道双重注意力机制实现通道特征的自适应
选择,但其注意力权重仅基于特征图的相对关系生成,未能充分利用脑电信号的
统计特性;Qin 等[103]设计的 ETCNet 集合高效通道注意力机制和时序卷积网络
(TCN),自适应提取通道特征并增强时域信息,其通过单一卷积核尺寸进行特
征提取,限制了模型对不同尺度时域特征的捕获能力;Li 等[104]提出的 MFRC-Net
通过时间多尺度残差卷积块和跨域双流空间卷积块创新性地实现了对 EEG 信号
的多尺度特征提取,但其三重损失函数需要精细调整超参数,且在特征融合过程
中可能存在信息冗余和干扰问题。
针对现有特征提取方法存在的局限性,本章基于多尺度卷积与注意力机制提
出了一 种多 尺度 时空 动态注 意力 网络 (Multi-Scale Spatio-Temporal Dynamic
Attention Network,MSTDAN),用于 MI-EEG 时空特征提取。首先阐述 MSTDAN
模型的整体设计思路;其次详细介绍模型中的各功能模块的原理;最后在三个公
开数据集上进行跨会话实验,全面评估模型性能。设计对比实验、消融实验以及


杭州电子科技大学硕士学位论文
14
关键超参数的敏感度分析,验证了所提出的 MSTDAN 模型在 MI-EEG 特征提取
上的有效性。
3.2 多尺度时空动态注意力网络(MSTDAN)
目前基于深度学习的 MI-EEG 特征提取方法在时空特征提取方面仍存在以
下局限性:现有模型虽然采用了多尺度卷积结构提取时域特征,但往往采用简单
的特征拼接方式进行融合,忽略了不同时间尺度特征间的非线性关联,无法充分
挖掘特征间的互补信息;在空间特征提取上,现有的大部分工作仅采用核大小为
(通道数,1)的卷积整合多个电极通道上的信息,不足以提取有效的空间特征。
另外,在空间特征提取过程中,大多数方法仅关注通道间的相对关联性,这种基
于相对关系的权重分配机制忽视了脑电信号中蕴含的重要统计信息,难以反映信
号能量分布的绝对差异,限制了模型对空间特征的表达能力;在深层时域特征提
取过程中,现有方法采用的串行特征提取结构不利于并行捕获不同时间尺度的动
态特征,容易导致长程依赖信息的丢失,限制了模型对复杂时域动态特征的捕获
能力。
因此,为了解决现有方法存在的局限性,本章构建了一种多尺度时空动态注
意力网络(MSTDAN)。MSTDAN 模型的整体结构如图 3.1 所示。
模型处理的运动想象脑电数据 X 表示为 RC T
X×
∈ ,这里 T 代表时间采样点
数,C 代表电极导联数。首先,通过多尺度动态特征选择模块(Multi-scale Dynamic
Feature Selection,MDFS)实现多尺度时域特征的并行提取与融合,该模块采用
不同时间尺度的卷积分支提取时域特征,并基于全局特征表示实现动态特征选择,
模块首先通过平均池化和最大池化获取多尺度特征的全局表示,然后基于这些全
局信息通过卷积操作生成自适应权重,最终实现多尺度特征的动态融合,有效解
决了现有方法中多尺度特征简单拼接的问题;其次,特征输入基于方差的统计注
意力模块(Statistical Variance Attention,SVA),该模块引入自适应空间注意力机
制,基于信号的方差统计特性动态调整通道权重以提取空间特征,增强了关键特
征的表达能力,克服了现有空间特征提取不充分以及忽视信号统计信息的局限;
然后,提取的特征输入到多时间尺度特征混合模块(Multi-Temporal Feature Mixer,
MTFM),该模块采用三分支并行结构提取多尺度深层时域特征,通过建模不同
尺度特征间的关联性实现特征优化,提升了模型对深层时域特征的捕获能力;最
后,经过平均池化和全连接层,模型输出相应的运动想象类别预测结果。


杭州电子科技大学硕士学位论文
15
图 3.1 MSTDAN 模型结构图
3.2.1 MDFS 模块
MDFS 的设计旨在解决现有方法中多尺度特征简单拼接的问题。该模块结合
多尺度时间卷积和全局注意力机制,实现了对运动想象脑电信号时域特征的自适
应提取与融合。模块结构如图 3.2 所示。
AvgPool
MaxPool
(1,64)
(1,32)
(1,16)
多尺度动态特征选择模块
Proj_in
Channel Normalization
Pointwise Conv 1D
Flatten
基于方差的统计注意力模块
多时间尺度特征混合模块
Conv Batch
Norm Activation Dropout
C
T
F
C
T
F
C
T
F
CC
T
3F
Conv1D C
T
3F
C
T
3F
Gating Adaptation
....
Global Context Embedding
Proj_out
(1,4)
(1,16)
(1,8)
AvgPool
(1,4)
(1,16)
(1,8)
C
Cross recombination
C Concatenate Addition Multiply


杭州电子科技大学硕士学位论文
16
图 3.2 MDFS 模块结构图
首先,该模块设计了三个并行的时间卷积分支,卷积核大小分别为 k1=(1,
64)、k2=(1,32)、k3=(1,16),在 250Hz 采样率下对应约 256ms、128ms 和
64ms 的时间窗口。这种设计使网络能够分别提取与 4Hz、8Hz 和 16Hz 以上频率
相关的时域特征,有效覆盖了与 MI 相关的 θ(4-7Hz)、α(8-13Hz)和 β(13
30Hz)节律。每个分支的卷积操作如式(3.1)所示。并行的多尺度设计可以同时捕
获不同时间跨度的时域特征,避免了串行结构中的信息损失问题。
( ) 1, 2,3
ii
X = Conv X,k ,i = (2.1)
其中 ki 为第 i 个分支的卷积核大小, RC T
X×
∈ 为输入的 MI-EEG 数据,C 为电极
导联数,T 为采样点数,Conv 为卷积操作, Xi 为第 i 个尺度下的时域特征图。
其次,由于 MI 过程中的个体差异和精神状态波动,ERD/ERS 现象的起始时
间和持续时间在不同被试间存在较大差异性。为了应对这种差异性,模块引入了
全局注意力机制。具体地,将三个不同时间尺度下获取的特征图进行拼接,如式
(3.2)所示:
123 123
[X ; X ; X ] = Concat([X , X , X ]) (2.2)
其中,Concat 表示在时间维度上的特征拼接操作, 1 2 3
[ X ; X ; X ] 为拼接过后的特
征图。
对拼接后的特征图进行平均池化和最大池化操作以提取全局上下文信息,如
式(3.3)(3.4)所示。这两种池化操作分别从不同角度捕获了特征的全局特性:平均
池化反映了特征的整体激活水平,最大池化则捕获了显著的局部响应。
123
([ ; ; ])
avg
P = AvgPool X X X (2.3)
Conv 1*64
Concat
Avg
Mvp
Conv
X
Conv 1*32
Conv 1*16
Sigmoid


杭州电子科技大学硕士学位论文
17
max 1 2 3
P = MaxPool([X ; X ; X ]) (2.4)
其中,AvgPool 为平均池化操作,MaxPool 为最大池化操作,Pavg 为通过平均池
化得到的全局特征表示,Pmax 为通过最大池化得到的全局特征表示。
基于提取的全局上下文信息,通过一维卷积层生成特征注意力权重,如式(3.5)
所示。根据全局上下文信息自适应地调整不同尺度特征的重要性,从而增强模型
对关键特征的感知能力。
( 1 ([ ; ]), 1, 2,3
i avg max
P =σ Conv D P P i = (2.5)
其中[ ; ]
avg max
P P 为池化特征的拼接结果,Conv1D 为一维卷积操作,用于学习池化
特征之间的非线性关系,σ为 sigmoid 激活函数,确保权重值在[0,1]范围内,Pi
为生成的注意力权重,每个 Pi 对应一个特征分支的权重向量。
最后,采用加权融合与残差连接相结合的方式进行特征融合,如式(3.6)所示:
3
1
ˆ ii i
X PX X
=
= ⋅+
∑ (2.6)
其中 RC T
X×
∈ 为输入的 MI-EEG 数据,作为残差连接项保证了原始信息的有效传
递,C 为电极导联数,T 为采样点数, i i
P ⋅ X 表示第 i 个特征分支与其对应权重的
加权结果,
3
1
ii i
PX
=
⋅
∑ 为基于注意力的特征融合操作, Xˆ 为最终输出的特征图。
多尺度特征动态融合方法能够自适应地调整不同时间尺度特征的重要性,通
过残差连接保证了信息传递的完整性。相比于传统的特征拼接方法,MDFS 模块
能够更好地处理 MI 过程中的时序动态变化,提高模型对关键特征的感知能力。
3.2.2 SVA 模块
研究表明,方差作为重要的统计特征,能够有效反映 MI-EEG 的能量波动和
稳定性特征。现有的大部分工作仅采用核大小为(通道数,1)的卷积整合多个
电极通道上的信息,不足以提取有效的空间特征。其次,现有方法主要依赖 MI
EEG 的通道间相对关系来分配注意力权重,忽视信号本身蕴含的统计特性,这限
制 了 模 型 对 空 间 特 征 的 提 取 能 力 。 受 门 控 通 道 变 换 [105] ( Gated Channel
Transformation,GCT)的启发,本文提出了基于方差的统计注意力机制(SVA),
实现了对 MI-EEG 空间特征的自适应提取。该模块结构如图 3.3 所示,包含全局
上下文嵌入、通道归一化和门控自适应三部分。


杭州电子科技大学硕士学位论文
18
图 3.3 SVA 模块结构图
首先,考虑到 MI 过程中不同通道的活跃程度存在显著差异,模块将 MI-EEG
的方差统计特征作为全局上下文嵌入。MDFS 模块提取了丰富的时域特征,但其
卷积操作可能会损失部分原始 MI-EEG 的统计特性信息。因此,选择直接从原始
MI-EEG 中提取方差统计特征来生成门控权重。对于 MI-EEG 这种离散的时间序
列信号,期望可以通过算术平均来估计,因此使用滑动窗口平均池化来计算局部
时间窗口内的期望和方差,如式(3.7)所示。滑动窗口大小设置为 250ms。这一设
置基于 MI 过程中 ERD/ERS 现象的时间特性:MI 任务通常会引起 θ(4-7Hz)、
α(8-13Hz)和 β(13-30Hz)节律频段的能量变化,这些变化在 200-300ms 的时
间窗口内最为显著。通过平均池化,可以有效估计信号在局部时间窗口内的统计
特征。
22
( ) ( ( ))
mean
Var = AvgPool X − AvgPool X (2.7)
其中, RC T
X×
∈ 为输入的原始 MI-EEG 数据,AvgPool 为 250ms 的滑动窗口平均
池化操作, ˆ
RC T
mean
Var ×
∈ 为不同时间窗口下的局部方差,Tˆ 为时间维度经滑动窗
口操作后的长度。
对整个时间维度上的局部方差取均值,得到通道级别的统计特征,如式(3.8)
所示:
()
mean
S =α⋅ AvgPool Var (2.8)
其中,AvgPool 为在整个时间维度上的平均池化操作, 1
RC
α×
∈ 为可学习的参数,
用于控制每个通道的权重, 1
RC
S×
∈ 为通道的统计特征。
其次,为了平衡不同通道间的统计特征分布,引入通道归一化操作。通过 L2
范数归一化将不同通道间的统计特征标准化,稳定通道间的权重分布,如式(3.9)
所示:
÷
tanh
全局上下文嵌入
通道归一化
门控自适应
Conv 1*1
AvgPool


杭州电子科技大学硕士学位论文
19
1 22
2
1
ˆ
[( ) ]
C
C
CS CS
SS Sε
=
==
+
∑
(2.9)
其中,ε为一个小的常数,用来避免零点处求导问题,C 为电极导联数, 2
S为
L2 范数, Sˆ 为归一化后的统计特征。
然后,基于归一化后的方差统计特征,使用可学习的门控机制对每个脑电通
道实现自适应加权。由于通道归一化操作本身不包含可学习参数,设计了可学习
的权重和偏置来控制每个通道门控的激活程度,如式(3.10)所示:
ˆ
G = 1+ tanh(γS + β) (2.10)
其中 γ 为门控权重,β 为偏置,tanh 为激活函数,确保门控权重在[-1,1]范围内变
化, 1
RC
G×
∈ 为基于原始 MI-EEG 的方差统计特征计算得到的门控权重向量。
对每个脑电通道,将基于其原始 MI-EEG 计算得到的门控权重应用于 MDFS
模块对应通道的输出,如式(3.11)所示:
ˆ
svg
X = G ⋅ X (2.11)
其中 ˆ RC T
X×
∈ 为 MDFS 模块输出的特征图,Xsvg 为加权后的特征图。
最后,为了进一步捕获加权后不同脑区之间的空间关系,使用一维点卷积进
行空间特征提取,如式(3.12)所示:
1( )
c svg
X = Conv D X (2.12)
其中,Conv1D 表示核大小为 1 的一维点卷积操作,用于学习加权后通道间的空
间依赖关系,Xc 为提取空间特征之后输出的特征图。
在空间特征提取之后添加平均池化操作进行特征压缩,降低特征维度并进一
步提取关键信息,如式(3.13)所示:
( , 4)
c
X = AvgPool F stride =
 (2.13)
其中,AvgPool 为平均池化操作,stride 为池化步长, X 为降维过后的特征图。
该模块充分利用了原始 MI-EEG 的统计特性,通过自适应门控注意力机制实
现了空间特征的动态增强。与传统的基于相对关系的注意力机制相比,该模块能
够更准确地捕获不同脑区的活跃程度,增强了特征的区分性和表征能力。
3.2.3 MTFM 模块
MTFM 模块通过多分支并行结构和特征交叉重组机制实现了对 MI-EEG 深
层多尺度时域特征的有效提取和融合。MTFM 模块结构如图 3.4 所示。


杭州电子科技大学硕士学位论文
20
图 3.4 MTFM 模块结构图
模块首先通过特征嵌入扩展操作增强特征表达能力。采用线性投影扩展将输
入特征的通道维度扩展为原来的 3 倍,为后续的多尺度特征提取和交叉重组提供
更大的特征表达空间,如式(3.14)所示:
()
Xl = Proj X
  (2.14)
其中, X 为 SVA 模块输出的特征图,Proj 为投影扩展操作, X l 为扩展后的特征
图。
基于扩展后的特征空间,模块设计了三个并行的深层时域特征提取分支,采
用不同感受野大小的卷积核对特征进行多尺度处理,如式(3.15)所示。由于在 SVA
模块的最后使用了平均池化(stride=4)进行特征降维,为了保持特征表达的一致
性,将卷积核大小设置为 k1=(1,16)、k2=(1,8)、k3=(1,4)。
1
1
1
1
2
3
()
()
()
S l
P l
V l
X = Conv X k
X = Conv X k
X = Conv X k



,
,
,
(2.15)
其中,Conv 为卷积操作, 1 1 1
,,
S PV lll
XXX
   分别为三个不同时间尺度下提取的深层时
域特征图。
为了充分利用不同尺度深层时域特征间的关联性,模块引入特征分块和交叉
重组机制。通过特征的分块重组实现了不同时间尺度特征之间的深度交互。将每
个分支的特征等分为三块,并按照特定的组合方式进行重组,如式(3.16)所示,
这种交叉重组策略增强了特征的互补性融合。
1_1 1_ 2 1_3
1_1 1_ 2 1_3
1_1 1_ 2 1_3
[, , ]
[, , ]
[, , ]
S PV
S
l lll
VS P
P
l ll l
PV S
V
l ll l
X Concat X X X
X Concat X X X
X Concat X X X
=
=
=
 
  
 
(2.16)
其中, 1_1,2,3 1_1,2,3 1_1,2,3
,,
S PV lll
XXX
   为不同尺度特征的第 i 个(i=1,2,3)分块,Concat 为
特征拼接操作, , P ,
SV ll l
XX X
   为交叉重组之后的特征。
C
C
C
C
Conv 1*16
Conv 1*1
Conv 1*8
Conv 1*4
Conv 1*16
Conv 1*8
Conv 1*4
Conv 1*1


杭州电子科技大学硕士学位论文
21
然后,使用卷积对三个交叉重组之后的特征进行特征变换与降维,卷积核大
小设置为 k1=(1,16)、k2=(1,8)、k3=(1,4),对卷积后的多尺度特征进行融
合,如式(3.17)所示。在特征降维的同时,保留不同时间尺度上的关键信息。
2
2
2
222
1
2
3
()
()
()
[, , ]
SS ll
PP ll
VV ll
S PV l lll
X = Conv X k
X = Conv X k
X = Conv X k
X = Concat X X X




,
,
,
(2.17)
其中,Conv 为卷积操作, 2 2 2
,,
S PV lll
XXX
   分别为降维后的特征图,Concat 为特征拼
接操作,Xl 为拼接后的特征图。
最后,通过投影变换将特征映射回原始维度,利用池化操作对特征进行降维,
并添加残差连接以保持信息的完整性,避免模型过拟合,如式(3.18)所示:
( ( ), 2)
ol
X = AvgPool Proj X stride = + X (2.18)
其中, X 为 SVA 模块输出的特征图,Proj 为投影操作,AvgPool 为平均池化,
stride 为池化步长,Xo 为最终输出特征。
与现有方法在提取深层时域特征时使用串行结构的方法不同,本模块采用多
分支并行提取结构,避免了长程依赖信息的丢失。结构化的特征交互机制建立了
不同时间尺度特征间的动态关联。模块尾部的多尺度卷积降维设计和残差连接的
引入进一步保证了信息传递的完整性与网络训练的稳定性。
3.3 实验设置及结果分析
本节通过系统性实验,对 MSTDAN 模型的性能进行了详细评估。实验内容
主要包括三个方面:一是在多个公开数据集上与现有方法进行对比,客观评估模
型的特征提取效果;二是设计消融实验,验证各功能模块对提升模型总体性能的
有效性;三是超参数敏感性分析,确定参数与模型表现的对应关系,选出最优配
置。
3.3.1 数据集介绍
本章研究采用三个公开数据集评估模型性能:BCI Competition IV 的 2a(2A)
与 2b(2B)数据集,以及 High-Gamma(HGD)数据集。
(1)BCIC-IV-2a 数据集
BCIC-IV-2a 数据集[98]收集了 9 位健康被试者(A01-A09)的 MI-EEG 数据。
实验要求被试者执行左手、右手、双脚和舌头四类运动想象任务,使用 22 通道
EEG 和 3 通道 EOG 电极同步记录脑电和眼电信号。每位被试者在连续的前后两
天分别完成两个实验会话,作为训练和测试数据集。每个会话细分为 6 个实验轮


杭州电子科技大学硕士学位论文
22
次,被试者在每轮实验中共进行 48 次 MI 任务(每类任务 12 次)。数据集共包
含 576 次 MI 任务的 EEG 数据,其中训练集和测试集占 288 次。
采样率为 250Hz,采集过程中应用 0.5-100Hz 的带通滤波和 50Hz 的陷波滤
波,以抑制外部干扰。电极布局遵循国际 10-20 系统,主要覆盖感觉运动皮层区
域,如图 3.5 所示。
图 3.5 BCIC-IV-2a 数据集电极位置分布图
实验范式采用标准的 Graz-BCI 协议(图 3.6):实验开始时,电脑屏幕显示
固定不变的十字(t=0s),伴有简短的提示音;经过 2 秒后,屏幕出现指向特定方
向的箭头,持续约 1.25 秒,分为上、下、左或者右四个方向,分别对应想象舌
头、双脚、左手以及右手运动,要求被试者根据箭头方向反复执行相应的运动想
象任务,直到第 6 秒屏幕中的十字消失,进行短暂的休息。每一次 MI 任务持续
时间平均约为 8 秒。
根据实验范式,本文研究选取每次 MI 任务中 2-6 秒区间的信号,对其进行
4-47Hz 带通滤波以去除眼电、心电和工频干扰。将第一天的会话数据作为训练
集,第二天的会话数据作为测试集。
图 3.6 BCIC-IV-2a 数据集实验范式图
(2)BCIC-IV-2b 数据集
BCIC-IV-2b 数据集[99]收集了 9 位右利手健康被试者(B01-B09)的 MI-EEG
数据。实验要求被试者执行左手、右手二类运动想象任务,与 2A 数据集不同,
注视屏幕
提示 运动想象 休息
提示音
0 1 2 34 5 6 7 8
时间/秒


杭州电子科技大学硕士学位论文
23
仅使用 3 个 EEG 通道(C3、Cz、C4)和 3 个辅助 EOG 通道记录信号。每位被
试在当天完成五个实验会话,其中前两个会话无视觉反馈,后三个会话引入视觉
反馈机制。在无视觉反馈会话中,包含 4 个实验轮次,被试者在每轮实验中共进
行 40 次 MI 任务(每类任务 20 次),共计 160 次。引入视觉反馈机制的会话分
为 6 个实验轮次,被试者在每轮实验中共进行 20 次 MI 任务(每类任务 10 次),
共计 120 次。
该数据采集过程的参数设置与 2a 数据集一致(250Hz 采样率,相同滤波设
置),但选取极少的 EEG 电极,如图 3.7 所示,只保留与左右手运动想象最相关
的中央区电极。
图 3.7 BCIC-IV-2b 数据集 EEG 电极位置分布图
该数据集有其两种不同的实验范式:
(1)无反馈范式:实验开始时,电脑屏幕显示固定不变的十字(t=0s)。在
听到简短提示音的 1 秒后,屏幕出现指向特定方向的箭头,持续约 1.25 秒,分
为左右两个方向,对应想象左右手运动,要求被试者根据箭头方向反复执行相应
的运动想象任务,直到第 7 秒屏幕中的十字消失,进行短暂的休息。每一次 MI
任务持续时间平均约为 9 秒,如图 3.8(a)所示。
(2)视觉反馈范式:实验开始时,电脑屏幕显示灰色笑脸(t=0s)。在听到
简短提示音的 1 秒后,屏幕中给出方向指示,被试者需通过运动想象将屏幕中间
的笑脸往左或者往右移动,当正确移动时,屏幕中会变为绿色笑脸图案,反之则
为红色沮丧图案,以此形成反馈。在 7.5 秒时屏幕清空。进行 1-2 秒的短暂休息。
每一次 MI 任务时间约为 9 秒,如图 3.8(b)所示。
根据实验范式,本文研究选取每次 MI 任务中 3-7 秒区间的信号,对其进行
4-47Hz 带通滤波以去除眼电、心电和工频干扰。将前三个会话的数据作为训练
集,后两个会话的数据作为测试集。


杭州电子科技大学硕士学位论文
24
图 3.8 BCIC-IV-2b 数据集实验范式图
(3)HGD 数据集
HGD 数据集[45]收集了 14 名健康被试者(H01-H14)的 MI-EEG 数据。实验
要求被试者执行左手、右手、双脚和静息状态四类运动想象任务,使用 128 个
EEG 通道记录信号。每位被试在当天进行一组会话,包含 13 个实验轮次,每轮
实验中共进行 80 次 MI 任务(每类任务随机出现),共计 1040 次。
HGD 数据集使用 500Hz 的采样率,为最大幅度避免肌电干扰,要求被试在
执行 MI 任务中想象微小的动作(左右手对应敲击手指,双脚对应紧握脚趾,静
息状态对应无运动)。
实验范式中:实验开始时,电脑屏幕显示固定不变的十字。伴有简短的提示
音,屏幕出现指向特定方向的箭头,持续 4 秒,分为上、下、左或者右四个方向,
分别对应想象休息、双脚、左手以及右手运动,要求被试者根据箭头方向反复执
行相应的运动想象任务直至十字消失,进行短暂的休息。
本文研究中将 HGD 数据集重采样至 250Hz,选择 44 个关键电极通道的数
据以减少冗余。由于第 14 名被试(H14)的数据不完整,研究中排除了该被试数
据,仅使用其余 13 名被试的记录。根据实验范式,本文研究截取每次 MI 中持
续的 4 秒数据,对其进行 4-125Hz 的带通滤波以及 50Hz 陷波滤波,去除眼电、
心电和工频干扰。将前 11 轮的实验轮次中的数据作为训练集(约 880 次 MI 任
务),后 2 轮实验轮次中的数据作为测试集(约为 160 次 MI 任务)。
固定十字
提示 运动想象 休息
提示音
1 2 3 45 67 89
时间/秒 0
灰色笑脸 运动想象 休息
提示音
12 3 45 67 89
时间/秒 0
提示
(a)
(b)


杭州电子科技大学硕士学位论文
25
3.3.2 评价指标
为客观评估不同运动想象脑电信号分类算法的性能,本章研究采用评价指标:
分类准确率、标准差(Standard Deviation,Std)和 Kappa 系数。
(1)分类准确率(Accuracy)是评估分类模型最直观的性能指标,定义为被
正确分类的样本数量占总样本数量的百分比。计算公式如式(3.19)所示:
1 100%
c i
i TP
Accuracy =
=×
∑
总样本数 (2.19)
其中,其中,c 表示类别数量,TPi 表示第 i 类被正确分类的样本数。
(2)标准差(Standard Deviation,Std)在分类模型性能评估中,反映了该
模型在不同被试或不同实验条件下的稳定性。计算公式如式(3.20)所示:
2
1
1( )
n
i i
Std x
nμ
=
=−
∑ (2.20)
(3)Kappa 系数是一种考虑了随机正确分类可能性的评价指标,特别适用
于多类别和类别不平衡的分类问题。Kappa 系数衡量模型分类结果与随机分类的
差异程度,计算公式如式(3.21)所示:
1
oe
e
P -P
K = - P (2.21)
其中, Po 是观察一致性,即分类准确率, Pe 是期望一致性,即基于随机猜
测的预期准确率, Pe 的计算方法如式(3.22)所示:
2 1
c
ii e i
ab
PN
=
×
= ∑ (2.22)
其中,ai 是预测为第 i 类的样本总数,bi 实际属于第 i 类的样本总数,N 是
数据集中的样本总数,c 是类别总数。
Kappa 系数的取值范围为[−1,1]。Kappa 系数能够提供比准确率更客观的性
能评估,特别是在各类别样本数量不平衡时。
3.3.3 实验设置
实验采用三个公开的 MI-EEG 数据集进行同一受试者下的跨会话实验。2A
数据集:将第一天的会话数据作为训练集,第二天的会话数据作为测试集;2B 数
据集:将前三个会话的数据作为训练集,后两个会话的数据作为测试集;HGD 数
据集:将前 11 轮的实验轮次中的数据作为训练集(约 880 次 MI 任务),后 2 轮
实验轮次中的数据作为测试集(约为 160 次 MI 任务)。
MSTDAN 模型的具体参数设置如表 3-1 所示。模型中的所有卷积层(Conv2D
和 Conv1D)之后均依次连接 BatchNorm、ELU 激活函数和 Dropout,其中大部


杭州电子科技大学硕士学位论文
26
分 Dropout 率为 0.25,仅在 D2 层后和 Linear 前的 Dropout 率为 0.5。
本章研究实验环境采用 Intel Core i7-12700K 处理器、NVIDIA RTX 3090Ti 显
卡(*2)、128GB(DDR4 3600MHz)内存的硬件配置,搭配 Ubuntu 20.04 系统、
PyTorch 1.13.0 深度学习框架(CUDA 11.7)和 Python 3.9.12 运行环境。
表 3-1 MSTDAN 模型具体参数
Module Layers Output size Details
MDFS
Input 22,1000,1
C1:Conv2D 22,1000,8 Kernel:1*64; num:8
C2:Conv2D 22,1000,8 Kernel:1*32; num:8
C3:Conv2D 22,1000,8 Kernel:1*16; num:8
N1:Concat 22,1000,24
D1:Conv1D 22,1000,3 Kernel:7; num:3
N2:Concat 22,1000,24
SVA
V:Variance calculation 22,250 AvgPool-Kernel:250
A1:AvgPool 22,1 Kernel:250
W:Channel weighting 22,1000,24
D2:Conv1D 1000,48 Kernel:1; num:48
A2:AvgPool 250,48 Kernel:4
MTFM
C4:Conv2D 250,144 Kernel:1*1; num:144
C5:Conv2D 250,48 Kernel:1*16; num:48
C6:Conv2D 250,48 Kernel:1*8; num:48
C7:Conv2D 250,48 Kernel:1*4; num:48
SplitFeatures:chunk 3*(250,16)
N3:Concat 250,48
C8:Conv2D 250,12 Kernel:1*16; num:12
C9:Conv2D 250,12 Kernel:1*8; num:12
C10:Conv2D 250,12 Kernel:1*4; num:12
N4:Concat 250,36
C11:Conv2D 250,48 Kernel:1*1; num:48
Flatten
A3:AvgPool 125,48 Kernel:2
C12:Conv1D 125,8 Kernel:4; num:8
A4:AvgPool 62,8 Kernel:62
GlobalAvgPool 8
Linear 4
3.3.4 对比实验
对比实验中,选取了七种模型提取 MI-EEG 时空特征并进行分类:FBCSP、
EEGNet、EEG-TCNet、EEG-Inception、TCACNet、ETCNet 以及 MFRC-Net。模
型训练采用统一参数配置:Adam 优化器、0.001 初始学习率、32 批量大小、500
轮训练周期及交叉熵损失函数。模型性能评价指标选用准确率、Std 以及 Kappa


杭州电子科技大学硕士学位论文
27
系数。
表 3-2、3-3 和 3-4 分别展示了 MSTDAN 模型与对比方法在 2A、2B 和 HGD
三个数据集上的性能对比结果。
图 3.9-3.11 为不同数据集下各对比方法对应的平均混淆矩阵。混淆矩阵直观
展示了预测标签与实际标签的对应关系,其中矩阵每个位置的数值反映特定类别
组合的百分比。纵轴代表实际标签,横轴表示算法预测结果。对角线数值代表正
确识别的比例,非对角数值代表系统将某一类别误判为另一类别的比例。
表 3-2 2A 数据集下各模型性能指标
被试 FBCSP EEGNet EEG
TCNet
EEG
Inception
TCAC
Net
ETC
Net
MFRC
Net MSTDAN
A01 75.35 74.65 83.68 82.64 85.07 84.38 86.11 85.42
A02 55.90 52.43 56.94 61.81 63.89 57.30 65.63 71.18
A03 80.56 87.15 86.81 90.97 92.71 88.54 93.40 95.14
A04 60.42 58.33 74.65 78.13 79.51 76.74 81.25 84.38
A05 54.17 47.92 58.33 62.15 66.32 63.54 65.71 69.44
A06 46.53 51.04 56.60 58.33 63.19 58.33 64.24 63.54
A07 81.94 84.03 87.15 89.93 92.71 81.50 92.01 92.36
A08 80.21 79.86 85.07 85.76 86.81 84.72 87.15 91.32
A09 71.18 86.81 83.68 85.48 86.11 83.33 86.46 85.76
Avg 67.36 69.14 74.77 77.24 78.48 75.38 80.22 82.06
Std 13.21 16.50 13.61 12.96 11.11 12.26 11.80 11.26
Kappa 0.5648 0.5885 0.6636 0.6966 0.7131 0.6717 0.7362 0.7608


杭州电子科技大学硕士学位论文
28
图 3.9 各模型的平均混淆矩阵图(2a 数据集)
(a)FBCSP (b)EEGNet
(c)EEG-TCNet (d)EEG-Inception
(e)TCACNet (f)ETCNet
(g)MFRC-Net (h)MSTDAN


杭州电子科技大学硕士学位论文
29
如表 3-2 所示,在 2A 数据集的四分类任务中,MSTDAN 模型表现突出,平
均分类准确率达到 82.06%,相比其他所有对比模型至少提高 1.84%,Kappa 系数
达到 0.7608。从单独被试效果上分析,MSTDAN 模型在多数被试上展现优势。
相较于其他对比方法,MSTDAN 的特征提取机制更为精准:FBCSP 因受先验知
识的限制,平均准确率仅为 67.36%;EEGNet 模型在设计上追求轻量化,在特征
表达能力上有所不足;EEG-TCNet 和 EEG-Inception 分类准确率分别为 74.77%
和 77.24%,但它们未能充分利用脑电信号多尺度时域特征间的关联性,缺乏对
空间特征的自适应增强能力,性能低于 MSTDAN 模型;TCACNet 引入时间与通
道双重注意力机制自适应选择特征,平均分类准确率和 Kappa 系数分别为 78.48%
和 0.7131,然而其注意力计算过度依赖特征间的相对关系,忽视了信号本身的统
计特性,限制了模型对不同被试脑电模式的适应能力。ETCNet 分类准确率为
75.38%,表明 ETCNet 的扩张卷积能够捕获特定时序模式,但缺乏多尺度特征集
成能力;MFRC-Net 分类准确率为 80.22%,凭借其多尺度残差结构实现了较高的
特征提取效率,但与 MSTDAN 模型性能还有一定差距。
如图 3.9 所示,2A 数据集上各模型的平均混淆矩阵进一步证明了 MSTDAN
的分类优势。其对角线元素值普遍高于其他模型,表明各类别识别精度更高;非
对角线元素值较低,说明模型对不同 MI 任务的区分能力更强。
表 3-3 2B 数据集下各模型性能指标
被试 FBCSP EEGNet EEG
TCNet
EEG
Inception
TCAC
Net
ETC
Net
MFRC
Net MSTDAN
B01 71.25 76.88 79.38 80.63 82.50 81.88 83.13 85.63
B02 61.25 58.75 62.50 63.13 65.63 63.75 68.75 68.13
B03 61.88 59.38 64.38 66.25 67.50 65.00 68.13 69.38
B04 96.88 97.50 98.13 97.50 98.13 96.88 98.75 98.25
B05 92.50 83.13 95.63 97.52 96.88 93.75 96.88 97.50
B06 81.88 89.38 84.38 86.88 89.38 89.38 90.00 92.50
B07 79.38 85.00 85.63 87.50 87.50 83.75 88.13 90.00
B08 93.13 93.75 93.75 95.00 96.63 96.88 96.25 96.73
B09 88.75 90.00 89.38 90.63 92.50 91.88 93.13 94.38
Avg 80.77 81.53 83.68 85.00 86.29 84.79 87.02 88.06
Std 13.44 14.07 12.89 12.76 12.26 12.69 11.58 11.64
Kappa 0.6153 0.6306 0.6737 0.7001 0.7259 0.6959 0.7403 0.7611


杭州电子科技大学硕士学位论文
30
图 3.10 各模型的平均混淆矩阵图(2b 数据集)
(a)FBCSP (b)EEGNet
(c)EEG-TCNet (d)EEG-Inception
(e)TCACNet (f)ETCNet
(g)MFRC-Net (h)MSTDAN


杭州电子科技大学硕士学位论文
31
在 2B 数据集的二分类任务中,如表 3-3 所示,MSTDAN 模型同样表现卓
越,平均分类准确率达 88.06%,Kappa 系数高达 0.7611,相较其他对比方法分别
提升至少 1.04%和 0.0208,并在 9 名被试中的 5 名上获得最高分类精度。FBCSP
和 EEGNet 在二分类任务上有所提升但性能仍落后于深度模型。其他深度模型,
在个别被试上表现优于 MSTDAN 模型,如 EEG-Inception 在 B05 被试上表现优
异,ETCNet 在 B08 被试上表现优异,但它们未能充分提取多尺度时域特征,在
特征融合上也存在局限性,整体性能低于 MSTDAN;MFRC-Net 在 B02 和 B04
被试上表现优异,但整体性能与 MSTDAN 仍有差距。虽然 2B 数据集仅使用了
三个通道(C3、Cz 和 C4),但 MSTDAN 模型依然展现出优异性能,展示了其对
有限空间信息的高效利用能力。
如图 3.10 所示,2B 数据集上各模型的平均混淆矩阵进一步证明了 MSTDAN
在两类任务的识别中均表现优异,降低了相互间的误分率。
表 3-4 HGD 数据集下各模型性能指标
被试 FBCSP EEGNet EEG
TCNet
EEG
Inception
TCAC
Net
ETC
Net
MFRC
Net MSTDAN
H01 83.27 87.43 88.75 89.46 90.72 91.21 91.71 93.05
H02 82.43 85.71 90.21 90.37 90.89 91.92 98.02 95.96
H03 92.74 86.29 91.58 95.83 96.96 93.55 93.58 98.89
H04 87.92 92.53 94.31 93.57 95.19 98.01 95.37 97.69
H05 89.63 93.64 89.42 89.75 95.58 96.69 92.44 91.83
H06 85.36 87.52 92.87 95.68 92.07 94.91 96.09 98.59
H07 83.92 93.16 94.21 91.25 95.81 94.32 94.28 94.81
H08 93.47 94.45 94.83 95.21 92.62 91.39 90.95 95.25
H09 84.25 92.86 95.14 94.38 90.52 93.31 95.08 95.18
H10 93.17 96.35 87.36 88.74 94.36 91.29 98.04 91.26
H11 81.28 84.92 95.74 96.31 96.41 94.92 92.04 96.65
H12 92.47 82.17 90.47 93.27 96.84 98.53 97.65 94.68
H13 84.68 88.42 93.17 92.42 89.74 95.74 96.57 96.83
Avg 87.28 89.65 92.16 92.79 93.67 94.29 94.76 95.44
Std 4.49 4.39 2.71 2.65 2.66 2.49 2.47 2.38
Kappa 0.8303 0.8620 0.8954 0.9038 0.9156 0.9239 0.9301 0.9391


杭州电子科技大学硕士学位论文
32
图 3.11 各模型的平均混淆矩阵图(HGD 数据集)
(a)FBCSP (b)EEGNet
(c)EEG-TCNet (d)EEG-Inception
(e)TCACNet (f)ETCNet
(g)MFRC-Net (h)MSTDAN


杭州电子科技大学硕士学位论文
33
在通道数更多的 HGD 数据集上进行四分类任务时,MSTDAN 模型同样展
现出卓越性能,平均分类准确率达 95.44%,Kappa 系数高达 0.9391,相较其他方
法分别提升至少 0.68%和 0.09。各对比模型在高质量数据条件下性能差距缩小:
FBCSP 和 EEGNet(87.28%和 89.65%)性能虽有提升但仍明显落后;深度模型
如 TCACNet、ETCNet 和 MFRC-Net 表现接近(准确率分别为 93.67%、94.29%
和 94.76%),仍与 MSTDAN 存在较小的差距。MSTDAN 在个别被试上仍保持显
著优势,这主要得益于其结构设计:SVA 模块对 44 通道高维数据进行基于方差
的自适应加权,有效突出与运动想象相关的重要通道;MTFM 模块的特征交叉重
组机制则在高分辨率数据上构建更精确的特征表示。此外,MSTDAN 在 HGD 数
据集上的标准差仅为 2.38,低于其他方法,进一步证明了模型的高鲁棒性和优异
泛化能力。
如图 3.11 所示,HGD 数据集上各模型的平均混淆矩阵展现了 MSTDAN 模
型在各类别上的识别准确率均处于领先水平。
3.3.5 消融实验
本节在三个公开数据集上对模型中的模块进行消融实验分析,以此验证
MSTDAN 模型中各功能模块的有效性。使用 t-SNE 算法可视化特征分布,以此
展示各模块对特征提取能力的影响。表 3-5 为各模块进行消融实验得到的
MSTDAN 模型平均分类准确率。
消融实验设计如下:
(1)w/o. MDFS:移除 MDFS 模块中的动态加权机制,仅保留多尺度卷积
操作并进行简单特征拼接,不再基于全局特征表示生成自适应权重进行动态融合。
(2)w/o. SVA:移除 SVA 模块中基于方差统计的自适应加权功能,直接使
用 Conv1D 层提取空间特征,不计算原始信号的方差统计特性。
(3)w/o. MTFM:移除 MTFM 模块中的特征交叉重组机制,移除特征扩展
操作,直接通过两层多尺度卷积层处理特征并输出,不进行特征重组交互。
表 3-5 模块消融分析下模型平均分类准确率(%)
数据集 MSTDAN
w/o. MDFS
MSTDAN
w/o. SVA
MSTDAN
w/o. MTFM MSTDAN
2A 76.44 79.03 78.09 82.06
2B 83.88 85.59 84.88 88.06
HGD 92.44 93.86 93.32 95.59
从三个数据集中各选取一名代表被试(2A 数据集的 A09、2B 数据集的 B07
和 HGD 数据集的 H12),使用 t-SNE 算法可视化特征分布,其特征分布可视化
结果如图 3.12-3.14 所示。可视化结果展示了完整模型与去除单一功能模块情况
下的特征分布差异,特别是在类边界清晰度、类内聚集性及类间分离度方面的变


杭州电子科技大学硕士学位论文
34
化。
图 3.12 2A 数据集 A09 被试特征可视化图
由表 3-5 数据可知,移除 MDFS 模块后,模型在所有数据集上的分类准确率
均显著下降,其中在 2A 数据集上下降了 5.62%,在 2B 数据集和 HGD 数据集上
分别下降了 4.18%和 3.15%。这表明 MDFS 模块通过动态加权的方式融合多尺度
时域特征,有效提升了模型对运动想象相关时域模式的识别能力。简单的特征拼
接方式无法充分挖掘不同时间尺度特征间的关联性,导致重要的时域动态特征被
弱化。如图 3.12 可视化结果所示,移除 MDFS 模块后,特征分布边界模糊,类
间重叠区域增多,类内聚集度降低,反映了该模块对提升特征判别性的重要作用。


杭州电子科技大学硕士学位论文
35
图 3.13 2B 数据集 B07 被试特征可视化图
移除 SVA 模块后,模型分类准确率在 2A、2B 和 HGD 数据集上分别下降了
3.03%,2.47%和 1.73%。这证实了基于方差统计特征的通道加权策略能够有效增
强信号能量分布显著的脑区特征,特别是在运动想象任务中与任务相关度高的大
脑皮层区域。这种空间特征增强机制优于简单的空间卷积方式。图 3.13 展示的
特征可视化结果表明,SVA 模块的移除导致二分类任务的特征分界线变得不清
晰,在通道数较多的 HGD 数据集(44 通道)上,SVA 模块的作用更为突出,充
分验证了该模块在高维空间特征上的优化能力。


杭州电子科技大学硕士学位论文
36
图 3.14 HGD 数据集 H12 被试特征可视化图
移除 MTFM 模块导致模型准确率在三个数据集上分别下降 3.97%、3.18%和
2.27%,这一结果表明 MTFM 模块中的特征交叉重组策略对深层时域特征的优化
具有重要作用。该模块通过"三分块-三重交叉"的特征重组机制,建立不同时间尺
度特征间的动态关联,有效增强了深层时域特征的表达能力。如图 3.14 所示,完
整 MSTDAN 模型生成的特征分布更加紧凑,类间边界更为清晰,验证了 MTFM
模块对特征质量的提升效果。
3.3.6 超参数敏感度分析
为系统评估各超参数对 MSTDAN 模型性能的影响,本研究采用参数敏感度
分析方法对模型关键参数进行研究。实验采用单一变量调控策略,在保持其他参
数恒定的条件下,调整目标参数并记录模型性能指标变化。实验结果表明,不同
超参数对模型性能影响程度各异,且存在明显的最优区间。通过对多组实验结果
进行综合评估,确定了一组平衡参数配置,保证特征提取能力的同时控制了模型
的计算负担。
(1)卷积核数量
在 MSTDAN 模型中,卷积核数量是影响模型性能的关键因素之一,其直接影


杭州电子科技大学硕士学位论文
37
响特征表达能力和计算复杂度。本节对 MDFS 模块中三个分支的卷积核数量 F1、
SVA 模块后的通道融合卷积核数量 F2 以及 MTFM 模块中的卷积核数量 F3、F4 进
行实验分析。
实验结果如图 3.15 所示,MDFS 模块中三个分支的卷积核数量 F1 设置为 8
时,模型在三个数据集上平均分类准确率达到最高。随着 F1 增加到 16 或更高,
模型性能不再提升甚至轻微下降,这可能是因为参数过多导致模型过拟合。SVA
模块后的通道融合卷积核数量 F2 设置为 48 时性能最佳,这一设置使得通道融合
后的特征维度适中,既保留了足够的信息量,又避免了后续处理的计算负担。
MTFM 模块中的第一阶段卷积核数量 F3 设置为 16,第二阶段卷积核数量 F4 设
置为 12 时模型性能表现最佳。综合考虑性能和计算效率,采用 F1=8,F2=48,
F3=16,F4=12 卷积核数量配置。
图 3.15 不同卷积核数量下模型平均分类准确率
(2)卷积核尺寸
卷积核尺寸是决定模型感受野范围的关键参数,对捕获 MI-EEG 时域特征具
有决定性影响。本节对 MDFS 模块中三个分支的卷积核尺寸 k1、k2、k3 以及全局
特征提取卷积核尺寸 k4 组合进行实验分析。
图 3.16 展示了不同卷积核尺寸配置下的模型性能变化。MDFS 模块中三个


杭州电子科技大学硕士学位论文
38
分支的卷积核尺寸 k1、k2、k3 分别设置为 64、32、16 时,模型性能达到最佳水
平。这三种尺寸对应的时间窗口在 250Hz 采样率下分别为 256ms、128ms 和 64ms,
能够有效捕获与运动想象相关的 θ(4-7Hz)、α(8-13Hz)和 β(13-30Hz)节律
特征。继续增大卷积核尺寸,计算复杂度增加的同时,模型性能没有进一步的提
升。MDFS 中的全局特征提取卷积核尺寸 k4 设置为 7 时,模型获得最优分类性
能,该参数取值使卷积操作在捕获时域特征全局上下文信息的同时,保持较低的
参数复杂度。
图 3.16 不同卷积核尺寸下模型平均分类准确率
(3)学习率与批处理大小
学习率和批处理大小(Batch size)是影响神经网络训练过程的两个重要调节
参数。学习率决定每次参数更新的幅度大小,Batch size 影响每次迭代中使用的
样本数量,进而影响梯度计算的稳定性。
实验结果如图 3.17 所示。学习率从 0.01 降至 0.001 时,模型在 2A、2B 和
HGD 三个数据集上的准确率均显著提升,但当进一步降低至 0.0005 和 0.0001 时,
性能却出现不同程度的下滑。过高的学习率导致收敛不稳定,过低则降低优化效
率。Batch size 设置为 32 时,模型达到最优性能,过小或过大的 Batch size 都会
使模型效果降低。小批量训练增加了参数更新频率,但引入过高的梯度估计方差;
大批量训练提供了更精确的梯度方向,但是牺牲了训练的随机性与灵活性。综合
分析多组实验结果,使用学习率为 0.001 和批处理大小为 32 的超参数配置。


杭州电子科技大学硕士学位论文
39
图 3.17 不同训练超参数下模型平均分类准确率
3.4 本章小结
本章针对运动想象脑电信号分类任务中时空特征提取不充分的局限性,提出
了多尺度时空动态注意力网络(MSTDAN)模型。该模型结合多尺度卷积与注意
力机制,有效解决了现有方法在多尺度时域特征融合、空间特征提取和深层时域
特征优化方面的局限性。在三个公开数据集上的对比实验证明,MSTDAN 模型
在不同任务类型与数据特性条件下均表现出显著的性能优势和鲁棒性。各功能模
块的消融实验证实了其对提升特征提取能力的贡献。超参数敏感度分析确定了在
特征提取能力和计算复杂度之间的最佳平衡配置。综上所述,MSTDAN 模型在
MI-EEG 的时空特征分析上提供了新的解决方法。


杭州电子科技大学硕士学位论文
40
第 4 章 基于无负样本对比自监督学习的 MI-EEG 分类
4.1 引言
深度学习方法在 MI-EEG 分类上已经取得了显著成效。然而,监督学习方法
过度依赖于标注数据,使得模型的设计受限于特定的实验范式。在实际应用中,
高质量标注数据的收集也存在诸多挑战:其一,受试者间和受试者内的脑电信号
存在显著差异,限制了标注数据的泛化能力;其二,长时间脑电采集会引起受试
者疲劳,影响数据质量和标注准确性。这些因素制约了监督学习方法在 MI-BCI
中的实际应用效果。
受 Barlow Twins 损失函数[106]的启发,本章基于对比学习构建了一种无负样
本运动想象脑电信号解码框架。该框架有效消除了传统对比学习方法(如
SimCLR)对大量负样本的依赖,显著减轻了计算负担。框架结构如图 4.1 所示。
图 4.1 无负样本 MI-EEG 解码框架结构图
P
数据增强 MSTDAN
编码器 投影网络 嵌入向量 Barlow Twins
Loss
权重共享 权重共享
LBJ
P
自监督训练阶段(无标签)
冻结预训练模型所有参数
添加新全连接分类层
冻结MSTDAN骨干模块 (MDFS、SVA和MTFM模块)
解冻最终卷积层(final_conv)
新增分类器
线性探测
仅训练新增分类层 评估表示学习质量
微调
最小化参数更新 减少过拟合风险
下游任务


杭州电子科技大学硕士学位论文
41
使用自监督预训练方法,在训练过程中,对单个 EEG 样本数据应用两种随
机数据增强方法生成一对增强视图,通过 MSTDAN 编码器提取特征表示,然后
使用投影网络映射到嵌入向量空间,最后通过 Barlow Twins 损失函数优化模型
参数。该方法最大限度地增强了不同视图间的相似性,减少了嵌入向量内部的冗
余信息,使模型能够学习到运动想象脑电信号的本质特征。为评估预训练模型的
有效性,本章研究采用线性探测和微调两种下游任务适配策略。其中,线性探测
方法仅用来评估不同数据增强组合在预训练过程中对特征学习的影响。在确定最
优数据增强组合后,使用“预训练-微调”方法进行模型训练。通过跨会话和跨被
试实验,全面评估模型性能。系统分析标注数据比例、投影网络参数及超参数对
模型性能影响。
4.2 数据增强
选择合适的数据增强方法在对比学习方法中至关重要。合适的数据增强方法
能够在保留信号本质特征的同时创建多样化的训练样本,提升模型在特征提取时
的鲁棒性。MI-EEG 因其固有的非平稳性、信噪比低和个体差异大等特性,为数
据增强带来挑战。本章研究中,针对 MI-EEG 特性设计了 5 种数据增强方法。实
验数据集采样率均为 250Hz,数据长度为 4s(共 1000 个采样点)。在训练过程
中,对原始数据随机应用两种增强方法,以提高模型的鲁棒性和泛化能力。
(1)随机高斯噪声(Random Gaussian Noise, GN)
向原始 MI-EEG 中添加随机噪声,模拟实际脑电采集过程中可能出现的电子
设备噪声和肌电伪迹。对于一个脑电信号 RC T
X×
∈ ,其中 C 是通道数,T 是时间
点数,高斯噪声增强如式(4.1)所示:
2
X X (0,σ std (X ))
′ = +   (4.1)
其中, 2
 (0,σ std ( X )) 表示均值为 0,方差为σ2 std (X ) 的高斯分布。参数σ在
范围[0.05,0.15]中随机选择,确保噪声水平控制在原始信号标准差的 5%到 15%
之间。增强了模型在面对随机噪声时的抗干扰能力,同时不会破坏信号中与 MI
相关的关键特征。该方法有助于模型在低信噪比条件下保持稳定性,这对于运动
想象脑电信号尤为重要,因为运动想象信号的振幅通常较低,容易受到背景噪声
影响。
(2)随机裁剪(Random Cropping, RC)
在时间维度上随机截取 MI-EEG 的一部分,然后重采样回数据的原始长度,
模拟了信号的时间偏移和时长变化。这种增强方法促使模型关注信号的局部特征
而非绝对时间位置。对于原始信号 X,随机裁剪过程如式(4.2)所示:
X Resample(X [: , i ; j],T )
′ = (4.2)


杭州电子科技大学硕士学位论文
42
其中,i 和 j 分别是随机选择的起始和结束索引,满足 0 12
T
≤i< 和
12
T
T − < j<T 。
Resample(,T ) 表示将裁剪后的信号重采样至原始数据长度 T。随机起始点会在前
83 个采样点(信号的前 1
3 s)中选择,随机结束点会在最后 83 个采样点(信号的
后1
3 s)中选择。
此方法有助于模型学习对时间偏移不敏感的特征表示,增强其对不同范式的
运动想象起始时间的适应能力。实际 MI 任务中,受试者执行想象动作的确切时
间点往往存在变化,在听到提示音后,不同试次和不同受试者之间的反应时间也
有差异。随机裁剪模拟了这种时间变异性,使模型能够专注于运动想象的本质特
征而非其时间位置,从而提高了模型在跨会话和跨受试者任务中的泛化能力。
(3)随机带通滤波(Random Bandpass Filtering, BF)
在预定义频率范围内随机选择低切频率和高切频率,对信号应用带通滤波器。
这种增强方法模拟了不同脑电采集设备的频率响应差异,同时帮助模型关注特定
频带中的重要特征。对于信号 X,带通滤波增强如式(4.3)所示:
(, , )
lh
X BPF X f f
′ = (4.3)
其中, ( , , )
lh
BPF  f f 表示截止频率为 fl 和 fh 的带通滤波器, fl 从[1,11]Hz 范围内
随机选择, fh 从[40,50]Hz 分为内随机选择。在不同样本中随机保留或强调与 MI
相关的不同脑电节律组合,包括 θ(4-7 Hz),α(8-13 Hz)和 β(13-30 Hz)。通
过随机变化频带组合,模型可以学习到频域上更具泛化能力的特征表示,减少对
特定频率的依赖。
(4)随机时间掩码(Random Time Masking, TM)
使用 MI-EEG 信号的平均值替换信号中随机选择的一段时间窗口,模拟了脑
电采集过程中可能出现的短暂数据丢失或伪影现象。这种增强方法促使模型学习
更鲁棒的特征表示,减少对单个时间片段的依赖。增强过程如式(4.4)所示:
X [:, s : s ω] X
′ + = (4.4)
其中,s 是随机选择的起始时间点,X 是原始信号 X 的均值,ω是掩码窗口宽度,
具体数值为[ , ]
16 8
T T 。对于 250Hz 的采样率和 4 秒的信号长度,掩码窗口宽度在
约 63 到 125 个时间点之间。这确保遮蔽区域既不会太小而无效,也不会太大而
破坏关键信息。通过这种方法,增强模型在处理部分信息缺失时的分类能力。
(5)随机排列(Random Permutation, RP)
将信号分割成几个时间段,对其随机重新排序,来模拟时间结构的变化。这


杭州电子科技大学硕士学位论文
43
种方法有助于模型学习信号的局部时频特性,而非仅依赖全局时间模式。对于信
号 X,随机排列过程如式(4.5)所示:
(1) (2) ( )
([ [: , ], [: , ] [: , ]])
n
X Concat X I X I X I
ππ π
′ = ,, (4.5)
其中, 1, 2 , , n
I I  I 是将时间轴分割为 n 个不重叠区间的索引集合,π 是这些区间
的一个随机排列,Concat 表示沿时间维度连接这些重排后的信号段。在本研究
中,将信号分为 n=6 个时间段,在保持每个段内时间连续性的同时引入全局时间
结构的变化。对于 250Hz 的采样率和 4 秒的信号长度,每个时间段约包含 167 时
间点。
图 4.2 为 2A 数据集中 A09 被试 C3 通道的原始 MI-EEG 及其经过不同增强
方法处理后的波形对比,展示了各种数据增强方法对原始信号的影响。
图 4.2 数据增强对比图
4.3 MSTDAN 编码网络
编码网络是对比学习框架中提取特征表示的核心组件。本章研究将第三章设
计的 MSTDAN 模型作为编码器,用于从增强后的脑电数据中提取丰富的时空表
示。MSTDAN 编码器输出固定维度的特征向量,该向量捕获了运动想象脑电信
号的核心时空特征。
4.4 投影网络
投影网络将编码器输出的特征向量映射到归一化的嵌入空间,是实现有效对
比学习的关键组件。本章研究中,投影网络采用多层感知机(MLP)结构,包含


杭州电子科技大学硕士学位论文
44
一个隐藏层和 ReLU 激活函数。具体操作如式(4.6)所示:
2
R (; )
dz
p
Z
Z Z pr
Zθ
′′
=∈ =
′ , (4.6)
其中,r 是 MSTDAN 编码器输出的表示向量, ( ; p )
p r θ 是投影网络的映射函数,
θp 表示可学习参数, dz 表示嵌入向量的维度。
投影网络创建了一个适合应用 Barlow Twins 损失函数的嵌入空间。将不同
增强视图的表示向量映射到该空间,模型能够有效学习特征间的冗余和不变性关
系。这种映射有助于简化特征分布,提高对比学习的效率和稳定性。
4.5 Barlow Twins 损失函数
传统对比学习方法(如 SimCLR)需要大量负样本对,这增加了计算复杂度,
同时模型对批量大小敏感。本章研究中采用 Barlow Twins 损失函数,它通过优化
表示向量的互相关矩阵来实现对比学习,无需负样本。
Barlow Twins 损失函数包含两个关键项:不变项和冗余减少项。具体实现如
式(4.7)所示:
22
(1 )
BT ii ij i i ji
£ Cλ C
≠
−+
∑ ∑∑
 (4.7)
其中,λ为可调节的超参数,用于平衡两项的重要性,C 表示跨批次维度计算的
交叉相关矩阵,大小取决于网络输出维度,矩阵中的数值取值范围为[-1,1]。具体
计算如式所示:
,,
22 ,,
() ( )
AB bi b j
b
ij A B bi b j
bb
zz
C
zz
∑
∑∑
 (4.8)
其中,b 表示批次样本,i 和 j 表示网络输出向量的维度, ,
A bi
z 表示批次中第 b 个
样本经第一种增强方法处理后,通过编码器和投影网络得到的嵌入向量的第 i 个
维度值, B
b, j
z 表示批次中第 b 个样本经第二种增强方法处理后,得到的嵌入向量
的第 j 个维度值。
损失函数的不变项(第一项)确保嵌入向量在应用数据增强变换后保持不变,
通过将交叉相关矩阵的对角元素设为 1 来实现。冗余减少项(第二项)通过将矩
阵的非对角元素设为 0,最小化嵌入向量不同分量之间的相关性。这种冗余减少
的操作确保输出单元包含关于样本的多样化、非冗余信息。Barlow Twins 损失函
数的这种双重约束机制使模型能够学习到数据的本质特征,同时避免了信息崩溃
问题,即所有样本映射到相同的表示空间。消除了对大量负样本的需求,简化了
训练过程。同时,损失函数计算仅涉及批内样本,计算复杂度较低。


杭州电子科技大学硕士学位论文
45
4.6 下游任务
为评估预训练模型的有效性,本章研究采用线性探测和微调两种下游任务适
配策略。
(1)线性探测
线性探测是评估预训练模型特征质量的有效方法。在此策略中,预训练的
MSTDAN 编码器参数完全冻结,仅在其输出特征上添加一个可训练的线性分类
层,用于预测运动想象类别。如式(4.9)所示:
y W f (x) b
θ
=  + (4.9)
其中,x 为输入数据, fθ 是固定参数的预训练 MSTDAN 编码器,W 和 b 是线性
分类器的可学习参数,y 为最终分类预测结果。线性探测的训练采用交叉熵损失
函数和 Adam 优化器。
(2)微调
微调策略通过解冻预训练模型的部分参数进行再训练,使特征更好地适应特
定下游任务。本研究采用部分微调策略,保持 MSTDAN 编码器前部分参数
(MDFS、SVA 和 MTFM 模块)固定,解冻最后卷积层和分类器的参数。微调
过程的损失函数使用带权重衰减的交叉熵损失,如式(4.10)所示:
2
,, 2
11
1 log( )
NC
ft i c i c ft ic
L yp
N αθ
==
=− +
∑ ∑ (4.10)
其中,N 为样本数量,C 为分类类别数量, yi,c 为第 i 个样本属于类别 c 的真实标
签(取值为 0 或 1), pi,c 为模型预测第 i 个样本属于类别 c 的概率,α是权重衰
减系数(设为 0.0001), ft
θ 是可微调参数集合, 2
ft 2
θ 为参数的 L2 范数平方,实
现权重衰减。
4.7 实验设置及结果分析
4.7.1 实验设置
本章实验采用与第三章相同的数据集、评价指标,详细介绍可参见 3.3.1 和
3.3.2 节。本章研究实验环境采用 Intel Core i7-12700K 处理器、NVIDIA RTX 3090Ti
显卡(*2)、128GB(DDR4 3600MHz)内存的硬件配置,搭配 Ubuntu 20.04 系统、
PyTorch 1.13.0 深度学习框架(CUDA 11.7)和 Python 3.9.12 运行环境。
使用 BCI Competition IV 的 2a(2A)与 2b(2B)数据集,以及 High-Gamma(HGD)
数据集进行本章实验。考虑到自监督预训练方法需要充分的训练数据量,本章研
究在预训练阶段将所有被试的数据合并使用。在实验设计上,进行跨会话与跨被
试两类下游任务对模型性能进行验证。


杭州电子科技大学硕士学位论文
46
(1)跨会话
使用 2A 与 2B 数据集进行跨会话验证。在 2A 数据集中,将第一天会话下
的所有被试者的数据用于预训练。下游任务中使用第一天会话下的数据进行训练,
第二天会话下的数据用于测试;将 2B 数据集的前三个会话的所有被试者的数据
用于预训练。下游任务中将前三个会话的数据作为训练集,后两个会话的数据作
为测试集。
(2)跨被试
在 HGD 数据集上进行跨被试验证,使用留一交叉验证策略:每次将 12 名
受试者的数据用于预训练和下游任务训练,剩余 1 名受试者的数据用于下游任务
的测试。
预训练的参数具体设置如下:Batchsize 设置为 256、初始学习率设为 0.001、
Barlow Twins 损失函数中λ设为 0.005、epoch 为 500,使用早停策略(patience=50)
以及 Adam 优化器。下游任务采用线性探测和微调两种策略。线性探测完全冻结
预训练编码器,仅训练新增分类层;微调则冻结核心模块,仅解冻最终卷积层和
分类器。具体参数如下:
(1)线性探测
该阶段下,分类准确率直接反映了编码器提取特征的有效性,通过比较不同
数据增强组合下的线性探测结果,客观评估各种增强策略对特征学习的影响,从
而确定最优的数据增强组合方法。该阶段的具体参数设置如下:
跨会话任务:添加线性分类层,学习率为 0.001;Batchsize 为 32;Adam 优
化器;epoch 为 100,早停策略(patience=50)。
跨被试任务:添加线性分类层,学习率为 0.001;Batchsize 为 64;Adam 优
化器;epoch 为 150,早停策略(patience=50)。
(2)微调
在确定最佳数据增强策略后,对预训练好的 MSTDAN 模型进行微调,该阶
段旨在评估自监督预训练结合微调后的模型在实际应用中的性能。具体参数如下:
跨会话任务:最终卷积层学习率为 0.0001,分类器学习率为 0.001;Batchsize
为 32;Adam 优化器,权重衰减 0.0001;epoch 为 200,早停策略(patience=50)。
跨被试任务:最终卷积层学习率为 0.0001,分类器学习率为 0.001;Batchsize
为 64;Adam 优化器,权重衰减 0.0002;epoch 为 300,早停策略(patience=50)。
4.7.2 数据增强影响分析
选择合适的数据增强方法在对比学习中至关重要。本节通过线性探测策略,
系统评估了不同数据增强组合对模型性能的影响,以确定最优的数据增强策略。
为全面评估各种数据增强组合的效果,在 2A、2B 和 HGD 数据集上进行了


杭州电子科技大学硕士学位论文
47
跨会话和跨被试实验。在自监督预训练阶段,分别使用五种数据增强方法(随机
高斯噪声 GN、随机裁剪 RC、随机带通滤波 BF、随机时间掩码 TM 和随机排列
RP)的两两组合构建框架的两个输入分支,共形成 25 种不同的组合方案。
以 2A 数据集为例,图 4.3 为 2A 数据集跨会话任务上不同数据增强组合的
分类准确率热力图。从热力图中可以明显观察到,随机裁剪(RC)与随机带通滤
波(BF)的组合在所有数据增强组合中表现最佳,分类准确率达到 60.2%。
图 4.3 不同数据增强方法的影响分析(线性探测)
在不同数据集和任务下,进一步对比了不同数据增强组合的性能,如图 4.4
所示。
图 4.4 不同数据集上数据增强组合的性能比较


杭州电子科技大学硕士学位论文
48
结果表明,随机裁剪与随机带通滤波的组合在所有实验设置中始终表现最佳。
这种组合策略使模型能够同时适应时间维度的变化和频率维度的选择性,从而学
习到更具判别力的 MI-EEG 特征表示。相比之下,包含随机排列(RP)的组合表
现相对较弱,这可能是因为随机排列破坏了脑电信号中重要的时间序列结构,影
响了与运动想象相关的时间动态特征的提取。随机时间掩码(TM)虽然不如
RC+BF 组合效果好,但在与随机裁剪组合时表现较为稳定,准确率达到 57.8%,
说明保留部分时间结构的同时引入适当的数据变化是有益的。
综上所述,在本章研究的所有后续实验中,将随机裁剪和随机带通滤波作为
无负样本 MI-EEG 解码框架的数据增强方法。
4.7.3 对比实验
本节将评估所提出的无负样本 MI-EEG 解码框架在运动想象脑电信号分类
任务上的性能,并与现有方法进行对比。选用 FBCSP、EEGNet、MSTDAN 以及
两种自监督学习方法 TRMINet(SSL)[75]和 MI-ResNeXt(SSL)[62]作为对比方
法。基于前一节确定的最优数据增强组合(随机裁剪+带通滤波),使用“预训练
-微调”的训练方法,在 2A、2B 数据集上进行跨会话实验,在 HGD 数据集上进
行跨被试实验,以全面评估模型在不同应用场景下的性能表现。分类性能如表 4
1 和表 4-2 所示。图 4.5-图 4.7 为对应的平均混淆矩阵。
表 4-1 跨会话任务的分类性能对比
方法
2a 数据集 2b 数据集
准确率(%) Kappa 准确率(%) Kappa
FBCSP 67.36±13.21 0.5648 80.77±12.67 0.6153
EEGNet 69.14±16.58 0.5885 81.53±13.26 0.6306
TRMINet(SSL) 71.25±14.27 0.6167 83.55±11.42 0.6710
MI-ResNeXt(SSL) 72.46±13.53 0.6328 83.75±11.58 0.6749
MSTDAN 82.06±11.25 0.7608 88.06±10.97 0.7611
MSTDAN(SSL) 79.85±10.97 0.7313 86.27±10.74 0.7254
表 4-2 跨被试任务的分类性能对比
方法 准确率(%) Kappa
FBCSP 62.35±7.82 0.4980
EEGNet 67.43±6.54 0.5658
TRMINet(SSL) 72.86±5.97 0.6381
MI-ResNeXt(SSL) 74.92±5.68 0.6657
MSTDAN 70.18±6.23 0.6024
MSTDAN(SSL) 76.54±5.32 0.6872


杭州电子科技大学硕士学位论文
49
图 4.5 各模型的平均混淆矩阵图(2a 数据集)
(a)FBCSP (b)EEGNet
(c)TRMINet(SSL) (d)MI-ResNeXt(SSL)
(e)MSTDAN (f)MSTDAN(SSL)


杭州电子科技大学硕士学位论文
50
图 4.6 各模型的平均混淆矩阵图(2b 数据集)
(a)FBCSP (b)EEGNet
(c)TRMINet(SSL) (d)MI-ResNeXt(SSL)
(e)MSTDAN (f)MSTDAN(SSL)


杭州电子科技大学硕士学位论文
51
图 4.7 各模型的平均混淆矩阵图(HGD 数据集)
如表 4-1 所示,在跨会话任务上,第三章提出的 MSTDAN 模型表现最为优
异,在 2A 数据集上准确率达到 82.06%,在 2B 数据集上达到 88.06%。结合无负
样本对比自监督学习策略的 SSL-MSTDAN 也表现出优秀的性能,其准确率仅略
低于直接训练的 MSTDAN,但显著优于其他对比方法,这可能是因为在有充分
(a)FBCSP (b)EEGNet
(c)TRMINet(SSL) (d)MI-ResNeXt(SSL)
(e)MSTDAN (f)MSTDAN(SSL)


杭州电子科技大学硕士学位论文
52
标注数据的情况下,监督学习方法往往能够直接学习到更具判别性的特征。此外,
SSL-MSTDAN 的标准差均低于其他方法,表明所提出的框架在分类任务上均具
有较高的泛化能力。
在跨被试任务上,如表 4-2 所示,SSL-MSTDAN 展现出了明显优势,分类
准确率达到 76.54%,Kappa 系数达到 0.6872,超过了所有对比方法。与跨会话任
务不同,在跨被试任务中 SSL-MSTDAN 的性能超过了 MSTDAN。这种现象与
Kostas 等人[77]的研究发现一致,他们指出自监督学习方法在面对分布差异较大
的数据时(如不同被试之间)往往能够展现出更强的泛化能力。这是因为在自监
督预训练过程学习到的特征表示更加注重数据的固有结构和信息,而不是过度拟
合特定被试的特征。此外,从标准差数据来看,SSL-MSTDAN 不仅平均性能最
佳,在不同被试间的性能波动最小(标准差为 5.32),表明该方法具有更稳定的
跨被试泛化能力。
4.7.4 投影网络参数影响分析
在无负样本 MI-EEG 解码框架中,投影网络是连接编码器和对比损失函数的
关键组件。以 HGD 数据集上进行跨被试实验为例,系统分析投影网络的关键参
数对 SSL-MSTDAN 分类性能的影响,主要包括投影网络输出维度、隐藏层维度
和非线性激活函数的选择。
(1)投影维度影响分析
投影维度是指投影网络输出向量的维度,它直接影响特征表示的丰富程度和
冗余度。为了量化投影维度对模型性能的影响,在保持其他参数不变的情况下,
对输出向量维度进行了系统测试,分别设置为 16、32、64、128、256、512 和 1024。
图 4.8 不同投影维度对 HGD 数据集跨被试分类性能的影响


杭州电子科技大学硕士学位论文
53
如图 4.8 所示,投影维度对分类性能有一定影响。当维度从 16 增加到 32 和
64 时,分类准确率提升,从 73.14%分别上升至 73.83%和 74.26%;继续增加维
度至 128 和 256 时,性能持续改善,分别达到 76.54%和 76.85%;然而,当维度
进一步增加到 512 和 1024 时,性能不但没有继续提升,反而出现轻微下降。这
一现象反映了投影维度对无负样本对比学习的影响:过小的维度无法提供足够的
表示空间,限制了模型捕获复杂特征的能力;过大的维度引入了过多冗余信息,
不仅增加了计算复杂度,还可能干扰模型对关键特征的学习,导致性能下降。
128 和 256 维度间性能相近,这表明在达到一定表示能力后,继续增加维度
带来的收益非常有限。从实用角度考虑,将投影维度设置为 128,在保持良好性
能的同时,显著减少模型参数量和计算负担。相比 256 维度,128 维度的模型参
数量减少了近一半,而性能仅下降 0.31%。
(2)隐藏层维度影响分析
除了输出维度外,投影网络隐藏层的维度同样对性能有重要影响。隐藏层作
为特征映射的中间表示,其容量直接关系到模型捕获复杂特征变换的能力。将输
出维度固定为 128,分析不同隐藏层维度对分类性能的影响,实验结果如图 4.9
所示。
图 4.9 不同隐藏层维度对 HGD 数据集跨被试分类性能的影响
从图中数据可以观察到:隐藏层维度与分类性能呈现非线性关系。在较低维
度范围,随着维度增加,性能显著提升,准确率从 71.32%上升至 76.54%,增幅
达 5.22%;而当维度扩大至 512 和 1024 时,性能提升急剧放缓,准确率仅微增
至 76.82%和 77.05%,增幅分别为 0.28%和 0.51%。
对比参数量的增长趋势,当隐藏层维度从 256 增加到 1024 时,参数量增长


杭州电子科技大学硕士学位论文
54
了 4 倍,但准确率仅提高 0.51%。过大的隐藏层不仅增加了计算负担,还提高了
模型过拟合的风险,特别是在 MI-EEG 数据集样本量有限的情况下。MI-EEG 具
有较高的个体差异性,在跨被试任务中,模型需要学习不同个体间共享的特征模
式,而避免过度拟合单个个体的特定模式。因此,适度的隐藏层维度能够在提供
足够表示能力的同时,限制模型复杂度,增强其在不同被试间的泛化能力。
综合准确率提升、计算效率和泛化能力考虑,选择 256 作为隐藏层的最优维
度。此配置既能保证较高的分类性能,又能有效控制计算复杂度。
(3)激活函数影响分析
投影网络中的激活函数决定了网络捕获复杂非线性关系的能力。为评估不同
激活函数对 SSL-MSTDAN 框架性能的影响,保持其他参数一致(输出维度 128,
隐藏层维度 256)的条件下,对比分析了三种常用激活函数:ReLU、Leaky ReLU
和 ELU。不同激活函数对各数据集分类性能的影响如图 4.10 所示。
图 4.10 不同激活函数对 HGD 数据集跨被试分类性能的影响
使用 ELU 激活函数的模型性能表现优于其他激活函数。与 ReLU 相比,ELU
能够产生负值输出,有助于将激活均值推向零,加速网络的收敛过程。ReLU 在
x<0 时输出为 0,导致某些神经元可能永远不会被激活;Leaky ReLU 通过在负区
间引入小斜率缓解了这一问题,但其线性负值部分可能不足以捕获复杂模式;而
ELU 提供了一个平滑的饱和曲线作为负值输出,这种设计在保持 ReLU 快速收
敛优势的同时,增强了对负值输入的建模能力。在运动想象脑电信号处理中,这
一特性尤为重要。脑电信号包含丰富的频率组分,其中 ERD/ERS 现象通常表现
为能量增加或减少,相应的特征值可能为正或负。ELU 激活函数能够更好地保留
这些双向变化的信息,使模型能够捕获更完整的神经活动模式。


杭州电子科技大学硕士学位论文
55
尽管 ELU 表现最佳,但三种激活函数之间的性能差异相对较小:ELU 相比
ReLU 仅提升了 0.89 个百分点,相比 Leaky ReLU 提升了 1.22 个百分点。激活函
数对训练稳定性的影响可能在更复杂的任务或更深的网络中更为明显。
综合考虑分类性能和训练稳定性,选择 ELU 作为投影网络的激活函数。
4.7.5 标注数据比例影响分析
为探究标注数据对无负样本 MI-EEG 解码框架性能的影响,本节在多个数据
集上进行实验。从完整训练集中随机抽取 10%、25%、50%、75%和 100%的样本
作为有标签数据子集。在预训练阶段,使用无标签的完整数据集进行训练;而在
下游任务微调阶段,仅使用有标签数据子集进行监督训练。图 4.11-4.13 展示了
各对比模型在不同标注数据比例下的分类性能。
实验结果表明,即使在标注数据有限的情况下,所提出的无负样本 MI-EEG
解码框架在跨会话与跨被试任务中均表现出显著优势。在低标注数据比例区域
(10%-25%),MSTDAN(SSL)模型表现尤为突出。当仅使用 10%标注数据时,
MSTDAN(SSL)在 2a、2b 和 HGD 数据集上的分类准确率分别达到 61.28%、
66.95%和 61.12%,不仅显著优于传统监督学习方法,还超越其他基于自监督学
习的方法(TRMINet(SSL)和 MI-ResNeXt(SSL))约 3-6 个百分点。随着标注
数据比例增加,MSTDAN(SSL)在三个数据集上使用 50%标注数据时,其性能
已分别达到全量标注数据下性能的 94.1%、94.5%和 93.4%。这些现象充分证实
了所提出的无负样本 MI-EEG 解码框架能够有效提取并利用未标注数据中的信
息,从而大幅降低对标注数据的依赖。
进一步分析发现,在相对简单的二分类任务(2b 数据集)中,所有方法的分
类性能普遍优于四分类(2a 和 HGD 数据集)任务。特别地,在跨被试任务中,
自监督学习方法与传统方法之间的性能差异更为显著,这一差异在低标注数据比
例条件下尤为突出。在 HGD 数据集上,当标注数据比例低于 25%时,传统方法
如 FBCSP 和 EEGNet 表现出明显的性能波动和不稳定性,而基于自监督学习的
方法则保持了相对平滑且稳定的性能增长曲线,充分证明了本文所提出的无负样
本 MI-EEG 解码框架在复杂分类任务中的鲁棒性以及对低标注数据场景的适应
能力。


杭州电子科技大学硕士学位论文
56
图 4.11 不同标注数据比例对模型性能影响(2a)
图 4.12 不同标注数据比例对模型性能影响(2b)


杭州电子科技大学硕士学位论文
57
图 4.13 不同标注数据比例对模型性能影响(HGD)
4.7.6 编码网络输出特征可视化
为了验证无负样本对比自监督学习预训练过程中编码网络是否能有效区分
不同样本的特征表示,本节使用 t-SNE 技术在 HGD 数据集上进行特征可视化。
将预训练完成后的 MSTDAN 编码网络和随机初始化网络提取的特征进行可视化,
进行对比评估预训练过程对特征区分能力的提升效果。图 4.14 展示了 HGD 数据
集上随机初始化网络与 SSL-MSTDAN 预训练后的特征分布对比。左图为网络权
重随机初始化时的特征散点图,右图为无负样本对比学习预训练后的特征散点图。
图 4.14 编码网络输出特征可视化


杭州电子科技大学硕士学位论文
58
从可视化结果看,随机初始化网络输出的特征呈现明显的无序分布和类别重
叠现象,四类运动想象(左手、右手、双脚和静息)的样本几乎无法区分,表明
初始网络完全缺乏类别区分能力。相比之下,经过预训练后,不同类别的特征形
成了明显分离的聚类,类内样本更加集中,类间距离显著增加。尽管对比学习并
非直接针对分类任务优化,但通过最大化同一样本不同增强视图间的表示一致性,
间接促进了类别间表示的分离,为下游分类任务奠定了良好基础。
4.7.7 超参数敏感度分析
为系统评估各超参数对无负样本 MI-EEG 解码框架(SSL-MSTDAN)的影
响,本节研究进行了系统的超参数敏感度分析。每个超参数的分析都保持其他参
数固定,仅调整目标参数,评估不同参数设置下在 2a、2b 和 HGD 三个数据集上
的分类性能。
(1)λ参数
λ 参数在 Barlow Twins 损失函数中用于平衡不变项与冗余减少项的重要性。
为分析其影响,设置了 0.002、0.005、0.01、0.02 和 0.05 五个不同的 λ 值。实验
结果如图 4.15 所示,λ=0.005 时,模型在三个数据集上均达到最佳性能。当 λ 值
过小时,冗余减少项的约束不足,导致特征表示中可能包含过多冗余信息;当 λ
值过大时,则可能过度减少特征间的相关性,损失有用的信息结构。
图 4.15 不同 λ 值对分类准确率的影响


杭州电子科技大学硕士学位论文
59
(2)学习率和批处理大小
图 4.16 不同训练超参数对分类准确率的影响
实验中设置了 0.0001、0.0005、0.001、0.005 和 0.01 五个不同的学习率值。
结果如图 4.16 所示,学习率为 0.001 时,模型在所有数据集上均达到最佳性能。
当学习率过小时,参数更新步长不足,导致模型收敛速度过慢,容易陷入局部最
优解,对于包含复杂时空特征的脑电信号,过小的学习率可能导致模型无法有效
跳出初始特征空间的局部结构,限制了特征表示的学习能力。当学习率过大时,
参数更新步长过大,优化过程容易跳过最优解区域,甚至可能导致训练不稳定,
表现为性能的显著下降。在 SSL-MSTDAN 框架中,过大的学习率可能导致模型
过度减少特征表示中的冗余信息,损失一些对下游任务有价值的信息结构,从而
影响分类性能。这种学习率影响模式在三个数据集上保持一致,表明该现象是模
型优化机制的内在特性,而非特定数据集的偶然结果。
批处理大小(Batch size)对 Barlow Twins 损失函数的影响尤为重要,因为该
损失函数是基于批内样本计算的互相关矩阵。实验中测试了 32、64、128、256 和
512 五个不同的批处理大小。结果表明,批处理大小为 256 时,模型在三个数据
集上均达到最佳性能。与传统的对比学习方法(如 SimCLR 框架)不同,本研究
提出的无负样本 MI-EEG 解码框架对批处理大小的依赖性显著降低。实验数据表
明,批处理大小从 32 增至 256 时,性能呈单调递增趋势;但增至 512 时性能略
降,分析认为这可能源于过大批量增加了优化难度,影响模型收敛质量。
4.8 本章小结
本章针对运动想象脑电信号分类中标注数据稀缺的问题,提出了一种基于无
负样本对比自监督学习的框架。在预训练阶段,设计了数据增强、编码网络、投
影网络、对比损失函数四部分。使用线性探测策略确定了表现最优的数据增强组
合。采用 Barlow Twins 损失函数消除了以往对比学习中对大量负样本的依赖。下
游任务中,使用“预训练-微调”的训练方法,进行跨会话与跨被试实验。仅需


杭州电子科技大学硕士学位论文
60
50%标注数据即可达到全量数据 94%以上的性能,且在跨被试任务中表现尤为突
出。实验证明,该框架不仅降低了对标注数据的依赖,还提高了模型的分类性能
与泛化能力,为 MI-BCI 系统的实际应用提供了新思路和有效解决方案。


杭州电子科技大学硕士学位论文
61
第 5 章 总结与展望
5.1 总结
运动想象脑机接口系统(MI-BCI)为运动功能障碍患者提供了一种非侵入式
的交互方式,通过解码用户运动想象过程中产生的脑电信号,实现意图到命令的
转换,在神经康复、辅助通信和人机交互等领域具有重要应用价值。
然而,当前 MI-EEG 解码研究仍存在以下挑战:一是脑电信号由于其固有的
非平稳特性,在不同域中呈现出独特的特征表达,现有特征提取方法在处理时空
域信息时未能充分学习到有效特征;二是标注数据获取成本高且耗时,需要专业
设备和严格的实验环境,造成训练数据稀缺。本文对运动想象脑电信号的时空特
征学习问题和标注数据稀缺问题展开研究,取得了以下主要成果:
(1)本文构建了一种多尺度时空动态注意力网络(Multi-Scale Spatio
Temporal Dynamic Attention Network,MSTDAN)。首先,该网络结合并行多尺度
卷积和全局注意力机制,提取不同时间尺度下的浅层时域特征并进行动态自适应
融合,有效捕获了特征间的非线性关联;其次,在空间特征提取上,设计了基于
方差的统计注意力机制,充分利用脑电信号的统计特性进行通道权重自适应调整,
增强对关键空间特征的感知能力;最后,使用并行多尺度卷积提取深层时域特征,
设计了特征重组机制来建立不同时间尺度特征间的动态关联,以此增强深层时域
特征的捕获能力。
实验结果表明,MSTDAN 模型在 BCIC-IV-2a、HGD 数据集上的四分类任务
中,模型平均分类准确率分别达到 82.06%和 95.44%,在 BCIC-IV-2b 数据集上的
二分类任务中,模型平均分类准确率达到 88.06%。
(2)本文构建了基于 Barlow Twins 的无负样本运动想象脑电信号解码框架。
在预训练策略上,系统性设计了五种针对 MI-EEG 特性的数据增强方法,通过线
性探测实验确定了随机裁剪与随机带通滤波的最优组合;采用 MSTDAN 作为特
征编码器,配合单隐藏层投影网络构建特征映射机制;引入 Barlow Twins 损失函
数,通过互相关矩阵优化实现无负样本对比学习。在下游适配上,建立了"预训
练-微调"的两阶段训练范式,实现预训练知识向具体分类任务的有效迁移。
该框架在两个方面实现了技术改进:一方面,消除了传统对比学习对大量负
样本的依赖,显著降低了计算复杂度和对批量大小的敏感性,提升了训练效率和
稳定性;另一方面,通过充分利用无标签数据进行特征表示学习,大幅减少了对
高质量标注数据的需求,使模型在仅使用 50%标注数据的条件下仍能达到全量


杭州电子科技大学硕士学位论文
62
数据 94%以上的性能水平。跨会话和跨被试实验结果显示,该框架在 BCIC-IV
2a、2b、HGD 三个数据集上分别达到 79.85%、86.27%和 76.54%的分类准确率,
特别在跨被试任务中展现出了优异的泛化能力。
5.2 展望
本文为运动想象脑电信号解码中存在的时空特征提取不充分和标注数据稀
缺问题提供了可行的解决方案。所提出的 MSTDAN 模型和无负样本 MI-EEG 解
码框架在多个数据集上表现出良好的分类效果与泛化能力。但考虑到 MI-EEG 分
析与应用的复杂性以及当前研究成果可能存在的局限性,未来研究可从以下几个
方向继续深入:
(1)当前 MSTDAN 模型在充分提取时空特征上表现优异,但模型结构相
对复杂,参数量大,计算资源需求高,这可能限制其在实时 BCI 系统和资源受限
设备中的应用。未来可以通过知识蒸馏和模型轻量化等技术降低模型复杂度,在
保持分类性能的同时提高运算效率。
(2)当前的无负样本 MI-EEG 解码框架虽然减少了对标注数据的依赖,但
仍存在一些局限性:当前的数据增强方法可能无法生成生理学上有意义的脑电数
据,未来研究可考虑模拟人脑活动来生成更真实的增强样本。另外,目前仅使用
了单一数据集进行预训练,未来可结合多个公开脑电数据集增强预训练网络的泛
化能力。


杭州电子科技大学硕士学位论文
64
参考文献
[1] Gao X, Xu D, Cheng M, et al. A BCI-based environmental controller for the
motion-disabled [J]. IEEE Transactions on Neural Systems and Rehabilitation
Engineering, 2003, 11(2): 137-140.
[2] Abiri R, Borhani S, Sellers E W, et al. A comprehensive review of EEG-based
brain–computer interface paradigms [J]. Journal of Neural Engineering, 2019,
16(1): 011001.
[3] 蔡楚杰,李四楠,刘天,等.运动想象脑机接口在脑卒中后上肢康复中的研究进
展[J].中国康复医学杂志,2023,38(06):851-857.
[4] Ang K K, Guan C. EEG-based strategies to detect motor imagery for control and
rehabilitation [J]. IEEE Transactions on Neural Systems and Rehabilitation
Engineering, 2017, 25(4): 392-401.
[5] Long J, Li Y, Wang H, et al. A hybrid brain computer interface to control the
direction and speed of a simulated or real wheelchair [J]. IEEE Transactions on
Neural Systems and Rehabilitation Engineering, 2012, 20(5): 720-729.
[6] Edelman B J, Meng J, Suma D, et al. Noninvasive neuroimaging enhances
continuous neural tracking for robotic device control [J]. Science Robotics, 2019,
4(31): eaaw6844.
[7] Cervera M A, Soekadar S R, Ushiba J, et al. Brain‐computer interfaces for post
stroke motor rehabilitation: a meta‐analysis [J]. Annals of Clinical and
Translational Neurology, 2018, 5(5): 651-663.
[8] Pichiorri F, Morone G, Petti M, et al. Brain–computer interface boosts motor
imagery practice during stroke recovery [J]. Annals of Neurology, 2015, 77(5):
851-865.
[9] Biasiucci A, Leeb R, Iturrate I, et al. Brain-actuated functional electrical
stimulation elicits lasting arm motor recovery after stroke[J]. Nature
Communications, 2018, 9(1): 1-13.
[10] Chaudhary U, Birbaumer N, Ramos-Murguialday A. Brain–computer interfaces
for communication and rehabilitation [J]. Nature Reviews Neurology, 2016, 12(9):
513-525.
[11] Contreras-Vidal J L, Bhagat N A, Brantley J, et al. Powered exoskeletons for


杭州电子科技大学硕士学位论文
65
bipedal locomotion after spinal cord injury [J]. Journal of Neural Engineering,
2016, 13(3): 031001.
[12] Lotte F, Bougrain L, Cichocki A, et al. A review of classification algorithms for
EEG-based brain–computer interfaces: a 10 year update [J]. Journal of Neural
Engineering, 2018, 15(3): 031005.
[13] Bashashati A, Fatourechi M, Ward R K, et al. A survey of signal processing
algorithms in brain–computer interfaces based on electrical brain signals [J].
Journal of Neural Engineering, 2007, 4(2): R32-57.
[14] Vidaurre C, Sannelli C, Müller K-R, et al. Co-adaptive calibration to improve BCI
efficiency [J]. Journal of Neural Engineering, 2011, 8(2): 025009.
[15] Neuper C, Scherer R, Reiner M, et al. Imagery of motor actions: Differential
effects of kinesthetic and visual–motor mode of imagery in single-trial EEG [J].
Cognitive Brain Research, 2005, 25(3): 668-677.
[16] Pfurtscheller G, Da Silva F L. Event-related EEG/MEG synchronization and
desynchronization: basic principles [J]. Clinical Neurophysiology, 1999, 110(11):
1842-1857.
[17] Blankertz B, Tomioka R, Lemm S, et al. Optimizing spatial filters for robust EEG
single-trial analysis [J]. IEEE Signal Processing Magazine, 2007, 25(1): 41-56.
[18] Myrden A, Chau T. Effects of user mental state on EEG-BCI performance [J].
Frontiers in Human Neuroscience, 2015, 9: 308.
[19] Chavarriaga R, Fried-Oken M, Kleih S, et al. Heading for new shores!
Overcoming pitfalls in BCI design [J]. Brain-Computer Interfaces, 2017, 4(1-2):
60-73.
[20] Sun L. Classification of imagery motor EEG data with wavelet denoising and
features selection [C]. 2016 International Conference on Wavelet Analysis and
Pattern Recognition (ICWAPR). Jeju, Korea (South): IEEE, 2016: 184-188.
[21] Kevric J, Subasi A. Comparison of signal decomposition methods in classification
of EEG signals for motor-imagery BCI system [J]. Biomedical Signal Processing
and Control, 2017, 31: 398-406.
[22] Herman P, Prasad G, McGinnity T M, et al. Comparative analysis of spectral
approaches to feature extraction for EEG-based motor imagery classification [J].
IEEE Transactions on Neural Systems and Rehabilitation Engineering, 2008,
16(4): 317-326.
[23] Ramoser H, Muller-Gerking J, Pfurtscheller G. Optimal spatial filtering of single


杭州电子科技大学硕士学位论文
66
trial EEG during imagined hand movement [J]. IEEE Transactions on
Rehabilitation Engineering, 2000, 8(4): 441-446.
[24] Vidaurre C, Krämer N, Blankertz B, et al. Time domain parameters as a feature
for EEG-based brain–computer interfaces [J]. Neural Networks, 2009, 22(9):
1313-1319.
[25] Ma Y, Ding X, She Q, et al. Classification of motor imagery EEG signals with
support vector machines and particle swarm optimization [J]. Computational and
Mathematical Methods in Medicine, 2016, 2016(1): 4941235.
[26] An Y, Lam H K, Ling S H. Multi-classification for EEG motor imagery signals
using data evaluation-based auto-selected regularized FBCSP and convolutional
neural network [J]. Neural Computing and Applications, 2023, 35(16): 12001
12027.
[27] Blankertz B, Dornhege G, Krauledat M, et al. The non-invasive Berlin brain
computer interface: fast acquisition of effective performance in untrained subjects
[J]. NeuroImage, 2007, 37(2): 539-550.
[28] Ang K K, Chin Z Y, Zhang H, et al. Filter bank common spatial pattern (FBCSP)
in brain-computer interface [C]. 2008 IEEE International Joint Conference on
Neural Networks (IJCNN). Hong Kong, China: IEEE, 2008: 2390-2397.
[29] Hwang J, Park S, Chi J. Improving multi-class motor imagery eeg classification
using overlapping sliding window and deep learning model [J]. Electronics, 2023,
12(5): 1186.
[30] Venkatachalam K, Devipriya A, Maniraj J, et al. A Novel Method of motor
imagery classification using eeg signal [J]. Artificial Intelligence in Medicine,
2020, 103: 101787.
[31] Gaur P, Gupta H, Chowdhury A, et al. A sliding window common spatial pattern
for enhancing motor imagery classification in EEG-BCI [J]. IEEE Transactions
on Instrumentation and Measurement, 2021, 70: 1-9.
[32] Lin C-L, Chen L-T. Improvement of brain–computer interface in motor imagery
training through the designing of a dynamic experiment and FBCSP [J]. Heliyon,
2023, 9(3):e13745.
[33] Dong E, Li C, Li L, et al. Classification of multi-class motor imagery with a novel
hierarchical SVM algorithm for brain–computer interfaces [J]. Medical &
Biological Engineering & Computing, 2017, 55(10): 1809-1818.
[34] Jin J, Miao Y, Daly I, et al. Correlation-based channel selection and regularized


杭州电子科技大学硕士学位论文
67
feature optimization for MI-based BCI [J]. Neural Networks, 2019, 118: 262-270.
[35] Huang G, Zhao Z, Zhang S, et al. Discrepancy between inter-and intra-subject
variability in EEG-based motor imagery brain-computer interface: Evidence from
multiple perspectives [J]. Frontiers in Neuroscience, 2023, 17: 1122661.
[36] Sadiq M T, Yu X, Yuan Z, et al. Toward the development of versatile brain
computer interfaces [J]. IEEE Transactions on Artificial Intelligence, 2021, 2(4):
314-328.
[37] Yu X, Aziz M Z, Sadiq M T, et al. A new framework for automatic detection of
motor and mental imagery EEG signals for robust BCI systems [J]. IEEE
Transactions on Instrumentation and Measurement, 2021, 70: 1-12.
[38] Wei C S, Keller C J, Li J, et al. Editorial:Inter-and intra-subject variability in brain
imaging and decoding[J]. Frontiers in Computational Neuroscience, 2021, 15:
791129.
[39] Köllőd C M, Adolf A, Iván K, et al. Deep comparisons of neural networks from
the EEGNet family[J]. Electronics, 2023, 12(12): 2743.
[40] Bashivan P, Rish I, Yeasin M, et al. Learning representations from EEG with deep
recurrent-convolutional neural networks[J]. arXiv preprint arXiv:1511.06448,
2015.
[41] Tabar Y R, Halici U. A novel deep learning approach for classification of EEG
motor imagery signals [J]. Journal of Neural Engineering, 2016, 14(1): 016003.
[42] Tibrewal N, Leeuwis N, Alimardani M. Classification of motor imagery EEG
using deep learning increases performance in inefficient BCI users [J]. Plos One,
2022, 17(7): e0268880.
[43] Lionakis E, Karampidis K, Papadourakis G. Current trends, challenges, and future
research directions of hybrid and deep learning techniques for motor imagery
brain–computer interface [J]. Multimodal Technologies and Interaction, 2023,
7(10): 95.
[44] Park S, Ha J, Kim L. Improving performance of motor imagery-based brain
computer interface in poorly performing subjects using a hybrid-imagery method
utilizing combined motor and somatosensory activity [J]. IEEE Transactions on
Neural Systems and Rehabilitation Engineering, 2023, 31: 1064-1074.
[45] Schirrmeister R T, Springenberg J T, Fiederer L D J, et al. Deep learning with
convolutional neural networks for EEG decoding and visualization [J]. Human
Brain Mapping, 2017, 38(11): 5391-5420.


杭州电子科技大学硕士学位论文
68
[46] Siuly S, Li Y, Zhang Y. EEG signal analysis and classification[J]. IEEE Trans
Neural Syst Rehabilit Eng, 2016, 11: 141-144.
[47] Banville H, Chehab O, Hyvärinen A, et al. Uncovering the structure of clinical
EEG signals with self-supervised learning [J]. Journal of Neural Engineering,
2021, 18(4): 046020.
[48] Li X, Zhang Y, Tiwari P, et al. EEG based emotion recognition: A tutorial and
review [J]. ACM Computing Surveys, 2022, 55(4): 1-57.
[49] Kim S-J, Lee D-H, Lee S-W. Rethinking CNN architecture for enhancing
decoding performance of motor imagery-based EEG signals [J]. IEEE Access,
2022, 10: 96984-96996.
[50] Li Y, Guo L, Liu Y, et al. A temporal-spectral-based squeeze-and-excitation
feature fusion network for motor imagery EEG decoding [J]. IEEE Transactions
on Neural Systems and Rehabilitation Engineering, 2021, 29: 1534-1545.
[51] Miao Z, Zhao M, Zhang X, et al. LMDA-Net: A lightweight multi-dimensional
attention network for general EEG-based brain-computer interfaces and
interpretability [J]. NeuroImage, 2023, 276: 120209.
[52] Wang Q, Wu B, Zhu P, et al. ECA-Net: Efficient channel attention for deep
convolutional neural networks [C]. 2020 IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR). Seattle, WA, USA: IEEE, 2020: 11531
11539.
[53] Wimpff M, Gizzi L, Zerfowski J, et al. EEG motor imagery decoding: A
framework for comparative analysis with channel attention mechanisms [J].
Journal of Neural Engineering, 2024, 21(3): 036020.
[54] Qin Y, Yang B, Ke S, et al. M-FANet: Multi-feature attention convolutional neural
network for motor imagery decoding [J]. IEEE Transactions on Neural Systems
and Rehabilitation Engineering, 2024, 32: 401-411.
[55] Hu J, Shen L, Sun G. Squeeze-and-excitation networks [C]. 2018 IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR). Salt Lake City,
UT, USA: IEEE, 2018: 7132-7141.
[56] Hou Y, Jia S, Lun X, et al. GCNs-net: a graph convolutional neural network
approach for decoding time-resolved eeg motor imagery signals [J]. IEEE
Transactions on Neural Networks and Learning Systems, 2024,35(6): 7312-7323.
[57] Tang X, Zhang J, Qi Y, et al. A spatial filter temporal graph convolutional network
for decoding motor imagery EEG signals [J]. Expert Systems with Applications,


杭州电子科技大学硕士学位论文
69
2024, 238: 121915.
[58] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need [C]. 31st
International Conference on Neural Information Processing Systems(NeurIPS).
Long Beach, California, USA: Curran Associates Inc, 2017: 6000-6010.
[59] Song Y, Zheng Q, Liu B, et al. EEG conformer: Convolutional transformer for
EEG decoding and visualization [J]. IEEE Transactions on Neural Systems and
Rehabilitation Engineering, 2023, 31: 710-719.
[60] Altaheri H, Muhammad G, Alsulaiman M. Physics-informed attention temporal
convolutional network for EEG-based motor imagery classification [J]. IEEE
Transactions on Industrial Informatics, 2023, 19(2): 2249-2258.
[61] Liu K, Yang T, Yu Z, et al. Msvtnet: Multi-scale vision transformer neural network
for eeg-based motor imagery decoding [J]. IEEE Journal of Biomedical and
Health Informatics, 2024, 28(12): 7126-7137.
[62] Lotey T, Keserwani P, Wasnik G, et al. Cross-session motor imagery EEG
classification using self-supervised contrastive learning [C]. 2022 26th
International Conference on Pattern Recognition (ICPR). Montreal, QC, Canada:
IEEE, 2022: 975-981.
[63] Kan H, Yu J, Huang J, et al. Self-supervised group meiosis contrastive learning
for eeg-based emotion recognition [J]. Applied Intelligence, 2023, 53(22): 27207
27225.
[64] Ali M, Hashim S. TransformNet: Self-supervised representation learning through
predicting geometric transformations [C]. 2022 19th International Bhurban
Conference on Applied Sciences and Technology (IBCAST). Islamabad, Pakistan:
IEEE, 2022: 296-301.
[65] Chen T, Kornblith S, Norouzi M, et al. A simple framework for contrastive
learning of visual representations [C] 37th International Conference on Machine
Learning(ICML). PmLR, 2020: 1597-1607.
[66] Xie Z, Zhang Z, Cao Y, et al. Simmim: A simple framework for masked image
modeling[C]. 2022 IEEE/CVF Conference on Computer Vision and Pattern
Recognition(CVPR). New Orleans, LA, USA: IEEE, 2022: 9643-9653.
[67] Jiang X, Zhao J, Du B, et al. Self-supervised contrastive learning for EEG-based
sleep staging[C]. 2021 International Joint Conference on Neural Networks
(IJCNN). Shenzhen, China: IEEE, 2021: 1-8.
[68] Rafiei M H, Gauthier L V, Adeli H, et al. Self-supervised learning for


杭州电子科技大学硕士学位论文
70
electroencephalography [J]. IEEE Transactions on Neural Networks and Learning
Systems, 2022, 35(2): 1457-1471.
[69] Yang C, Xiao C, Westover M B, et al. Self-supervised electroencephalogram
representation learning for automatic sleep staging: model development and
evaluation study [J]. JMIR AI, 2023, 2(1): e46769.
[70] Weng W, Gu Y, Guo S, et al. Self-supervised learning for electroencephalogram:
A systematic survey [J]. arXiv preprint arXiv:2401.05446, 2024.
[71] Kamsvåg S H, Størmer O. Exploring EEG self-supervised learning through
channel grouping [D]. Trondheim: NTNU, 2023.
[72] Wu Y, Daoudi M, Amad A. Transformer-based self-supervised multimodal
representation learning for wearable emotion recognition [J]. IEEE Transactions
on Affective Computing, 2023, 15(1): 157-172.
[73] Lee C-H, Kim H, Han H-j, et al. NeuroNet: A novel hybrid self-supervised
learning framework for sleep stage classification using single-channel EEG [J].
arXiv preprint arXiv:2404.17585, 2024.
[74] He Y, Lu Z, Wang J, et al. A self-supervised learning based channel attention
MLP-mixer network for motor imagery decoding [J]. IEEE Transactions on
Neural Systems and Rehabilitation Engineering, 2022, 30: 2406-2417.
[75] Ou Y, Sun S, Gan H, et al. An improved self-supervised learning for EEG
classification [J]. Math Biosci Eng, 2022, 19(7): 6907-6922.
[76] Del Pup F, Atzori M. Applications of self-supervised learning to biomedical
signals: A survey [J]. IEEE Access, 2023, 11: 144180-144203.
[77] Kostas D, Aroca-Ouellette S, Rudzicz F. BENDR: Using transformers and a
contrastive self-supervised learning task to learn from massive amounts of EEG
data [J]. Frontiers in Human Neuroscience, 2021, 15: 653659.
[78] Ding Z, Yang Y, Cheng X, et al. Self-supervision of feature transformation for
further improving supervised learning [J]. arXiv preprint arXiv:2106.04922, 2021.
[79] Navarro F, Watanabe C, Shit S, et al. Self-supervised pretext tasks in model
robustness & generalizability: A revisit from medical imaging perspective[C].
2022 44th Annual International Conference of the IEEE Engineering in Medicine
& Biology Society (EMBC). Glasgow, Scotland, United Kingdom: IEEE, 2022:
5074-5079.
[80] Liu X, Zhang F, Hou Z, et al. Self-supervised learning: Generative or contrastive
[J]. IEEE Transactions on Knowledge and Data Engineering, 2021, 35(1): 857


杭州电子科技大学硕士学位论文
71
876.
[81] Albelwi S. Survey on self-supervised learning: auxiliary pretext tasks and
contrastive learning methods in imaging [J]. Entropy, 2022, 24(4): 551.
[82] Zhang R, Zeng Y, Tong L, et al. ERP-WGAN: A data augmentation method for
EEG single-trial detection [J]. Journal of Neuroscience Methods, 2022, 376:
109621.
[83] Henry J C. Electroencephalography: basic principles, clinical applications, and
related fields[J]. Neurology, 2006, 67(11): 2092.
[84] Hamedi M, Salleh S-H, Noor A M. Electroencephalographic motor imagery brain
connectivity analysis for BCI: a review [J]. Neural Computation, 2016, 28(6):
999-1041.
[85] Pfurtscheller G, Neuper C. Motor imagery and direct brain-computer
communication [J]. Proceedings of the IEEE, 2001, 89(7): 1123-1134.
[86] Jeannerod M. Neural simulation of action: a unifying mechanism for motor
cognition [J]. Neuroimage, 2001, 14(1): S103-S109.
[87] Kasess C H, Windischberger C, Cunnington R, et al. The suppressive influence
of SMA on M1 in motor imagery revealed by fMRI and dynamic causal modeling
[J]. Neuroimage, 2008, 40(2): 828-837.
[88] Minguillon J, Lopez-Gordo M A, Pelayo F. Trends in EEG-BCI for daily-life:
Requirements for artifact removal [J]. Biomedical Signal Processing and Control,
2017, 31: 407-418.
[89] Shenoy P, Krauledat M, Blankertz B, et al. Towards adaptive classification for
BCI [J]. Journal of Neural Engineering, 2006, 3(1): R13-R23.
[90] Blankertz B, Sannelli C, Halder S, et al. Neurophysiological predictor of SMR
based BCI performance [J]. Neuroimage, 2010, 51(4): 1303-1309.
[91] Kingma D P, Welling M. Auto-encoding variational bayes[J]. arXiv preprint
arXiv: 1312.6114, 2013.
[92] Goodfellow I J, Pouget-Abadie J, Mirza M, et al. Generative adversarial nets [C].
28th International Conference on Neural Information Processing
Systems(NeurIPS). Montreal, Canada: MIT Press, 2014: 2672-2680.
[93] Gidaris S, Singh P, Komodakis N. Unsupervised representation learning by
predicting image rotations [J]. arXiv preprint arXiv:1803.07728, 2018.
[94] Oord A v d, Li Y, Vinyals O. Representation learning with contrastive predictive
coding [J]. arXiv preprint arXiv:1807.03748, 2018.


杭州电子科技大学硕士学位论文
72
[95] He K, Fan H, Wu Y, et al. Momentum contrast for unsupervised visual
representation learning [C]. 2020 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR). Seattle, WA, USA:IEEE, 2020: 9726-9735.
[96] Grill J-B, Strub F, Altché F, et al. Bootstrap your own latent-a new approach to
self-supervised learning [C]. 34th International Conference on Neural
Information Processing Systems(NeurIPS). Red Hook, NY, USA: Curran
Associates Inc, 2020: 21271-21284.
[97] Hadsell R, Chopra S, LeCun Y. Dimensionality reduction by learning an invariant
mapping [C]. 2006 IEEE Computer Society Conference on Computer Vision and
Pattern Recognition (CVPR'06). New York, NY, USA: IEEE, 2006: 1735-1742.
[98] Brunner C, Leeb R, Müller-Putz G, et al. BCI Competition 2008–Graz data set A
[J]. Institute for Knowledge Discovery (Laboratory of Brain-Computer
Interfaces), Graz University of Technology, 2008, 16(1-6): 1.
[99] Leeb R, Brunner C, Müller-Putz G, et al. BCI Competition 2008–Graz data set B
[J]. Graz University of Technology, Austria, 2008, 16: 1-6.
[100] Ingolfsson T M, Hersche M, Wang X, et al. EEG-TCNet: An accurate temporal
convolutional network for embedded motor-imagery brain–machine interfaces
[C]. 2020 IEEE International Conference on Systems, Man, and Cybernetics
(SMC). Toronto, ON, Canada: IEEE, 2020: 2958-2965.
[101] Santamaria-Vazquez E, Martinez-Cagigal V, Vaquerizo-Villar F, et al. EEG
inception: a novel deep convolutional neural network for assistive ERP-based
brain-computer interfaces [J]. IEEE Transactions on Neural Systems and
Rehabilitation Engineering, 2020, 28(12): 2773-82.
[102] Liu X, Shi R, Hui Q, et al. TCACNet: Temporal and channel attention
convolutional network for motor imagery classification of EEG-based BCI [J].
Information Processing & Management, 2022, 59(5): 103001.
[103] Qin Y, Li B, Wang W, et al. ETCNet: An EEG-based motor imagery classification
model combining efficient channel attention and temporal convolutional network
[J]. Brain Research, 2024, 1823: 148673.
[104] Li X, Yang Z, Tu X, et al. MFRC-Net: Multi-Scale Feature Residual
Convolutional Neural Network for Motor Imagery Decoding [J]. IEEE Journal of
Biomedical and Health Informatics, 2024.
[105] Yang Z, Zhu L, Wu Y, et al. Gated channel transformation for visual recognition
[C]. 2020 IEEE/CVF Conference on Computer Vision and Pattern


杭州电子科技大学硕士学位论文
73
Recognition(CVPR). Seattle, WA, USA: IEEE, 2020: 11797-11800.
[106] Zbontar J, Jing L, Misra I, et al. Barlow twins: Self-supervised learning via
redundancy reduction [C]. 38th International Conference on Machine
Learning(ICML). PMLR, 2021: 12310-12320.